{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "439af246-661f-4cec-9ca2-b6fed696c2cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\Desktop\\nba_third_try\\model\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import joblib\n",
    "import optuna\n",
    "from keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70001d67-b47c-4d06-8b6d-1c108e89f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Visitor</th>\n",
       "      <th>Decimal_Visitor</th>\n",
       "      <th>Home</th>\n",
       "      <th>Home_Decimal</th>\n",
       "      <th>Season</th>\n",
       "      <th>Home_Winner</th>\n",
       "      <th>Offense_MP_Visitor</th>\n",
       "      <th>Offense_FG_Visitor</th>\n",
       "      <th>Offense_FGA_Visitor</th>\n",
       "      <th>...</th>\n",
       "      <th>Defense_FTA_Home</th>\n",
       "      <th>Defense_FT%_Home</th>\n",
       "      <th>Defense_ORB_Home</th>\n",
       "      <th>Defense_DRB_Home</th>\n",
       "      <th>Defense_TRB_Home</th>\n",
       "      <th>Defense_AST_Home</th>\n",
       "      <th>Defense_STL_Home</th>\n",
       "      <th>Defense_BLK_Home</th>\n",
       "      <th>Defense_PF_Home</th>\n",
       "      <th>Defense_PTS_Home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>CLE</td>\n",
       "      <td>2.60</td>\n",
       "      <td>CHI</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>241.2</td>\n",
       "      <td>37.7</td>\n",
       "      <td>82.2</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>11.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>20.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>97.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>DET</td>\n",
       "      <td>3.55</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>241.8</td>\n",
       "      <td>37.1</td>\n",
       "      <td>85.8</td>\n",
       "      <td>...</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.764</td>\n",
       "      <td>11.6</td>\n",
       "      <td>32.1</td>\n",
       "      <td>43.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>97.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Visitor  Decimal_Visitor Home  Home_Decimal  Season  \\\n",
       "0           0     CLE             2.60  CHI      1.555556    2015   \n",
       "1           1     DET             3.55  ATL      1.312500    2015   \n",
       "\n",
       "   Home_Winner  Offense_MP_Visitor  Offense_FG_Visitor  Offense_FGA_Visitor  \\\n",
       "0            1               241.2                37.7                 82.2   \n",
       "1            0               241.8                37.1                 85.8   \n",
       "\n",
       "   ...  Defense_FTA_Home  Defense_FT%_Home  Defense_ORB_Home  \\\n",
       "0  ...              21.0             0.749              11.7   \n",
       "1  ...              20.1             0.764              11.6   \n",
       "\n",
       "   Defense_DRB_Home  Defense_TRB_Home  Defense_AST_Home  Defense_STL_Home  \\\n",
       "0              31.7              43.4              20.2               7.5   \n",
       "1              32.1              43.6              23.5               7.4   \n",
       "\n",
       "   Defense_BLK_Home  Defense_PF_Home  Defense_PTS_Home  \n",
       "0               5.4             21.2              97.8  \n",
       "1               4.9             19.6              97.1  \n",
       "\n",
       "[2 rows x 93 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_excel('../cleaning/final_df.xlsx')\n",
    "# df=df.drop('Unnamed: 0')\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1ac08ea-ee81-479f-ba3e-1bc2fd5cd4ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using iloc to drop the first column\n",
    "df = df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "152d960a-6af0-4887-a396-186c5ebb4bcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Visitor', 'Decimal_Visitor', 'Home', 'Home_Decimal', 'Season',\n",
       "       'Home_Winner', 'Offense_MP_Visitor', 'Offense_FG_Visitor',\n",
       "       'Offense_FGA_Visitor', 'Offense_FG%_Visitor', 'Offense_3P_Visitor',\n",
       "       'Offense_3PA_Visitor', 'Offense_3P%_Visitor', 'Offense_2P_Visitor',\n",
       "       'Offense_2PA_Visitor', 'Offense_2P%_Visitor', 'Offense_FT_Visitor',\n",
       "       'Offense_FTA_Visitor', 'Offense_FT%_Visitor', 'Offense_ORB_Visitor',\n",
       "       'Offense_DRB_Visitor', 'Offense_TRB_Visitor', 'Offense_AST_Visitor',\n",
       "       'Offense_STL_Visitor', 'Offense_BLK_Visitor', 'Offense_PF_Visitor',\n",
       "       'Offense_PTS_Visitor', 'Defense_Team_Visitor', 'Defense_MP_Visitor',\n",
       "       'Defense_FG_Visitor', 'Defense_FGA_Visitor', 'Defense_FG%_Visitor',\n",
       "       'Defense_3P_Visitor', 'Defense_3PA_Visitor', 'Defense_3P%_Visitor',\n",
       "       'Defense_2P_Visitor', 'Defense_2PA_Visitor', 'Defense_2P%_Visitor',\n",
       "       'Defense_FT_Visitor', 'Defense_FTA_Visitor', 'Defense_FT%_Visitor',\n",
       "       'Defense_ORB_Visitor', 'Defense_DRB_Visitor', 'Defense_TRB_Visitor',\n",
       "       'Defense_AST_Visitor', 'Defense_STL_Visitor', 'Defense_BLK_Visitor',\n",
       "       'Defense_PF_Visitor', 'Defense_PTS_Visitor', 'Offense_MP_Home',\n",
       "       'Offense_FG_Home', 'Offense_FGA_Home', 'Offense_FG%_Home',\n",
       "       'Offense_3P_Home', 'Offense_3PA_Home', 'Offense_3P%_Home',\n",
       "       'Offense_2P_Home', 'Offense_2PA_Home', 'Offense_2P%_Home',\n",
       "       'Offense_FT_Home', 'Offense_FTA_Home', 'Offense_FT%_Home',\n",
       "       'Offense_ORB_Home', 'Offense_DRB_Home', 'Offense_TRB_Home',\n",
       "       'Offense_AST_Home', 'Offense_STL_Home', 'Offense_BLK_Home',\n",
       "       'Offense_PF_Home', 'Offense_PTS_Home', 'Defense_Team_Home',\n",
       "       'Defense_MP_Home', 'Defense_FG_Home', 'Defense_FGA_Home',\n",
       "       'Defense_FG%_Home', 'Defense_3P_Home', 'Defense_3PA_Home',\n",
       "       'Defense_3P%_Home', 'Defense_2P_Home', 'Defense_2PA_Home',\n",
       "       'Defense_2P%_Home', 'Defense_FT_Home', 'Defense_FTA_Home',\n",
       "       'Defense_FT%_Home', 'Defense_ORB_Home', 'Defense_DRB_Home',\n",
       "       'Defense_TRB_Home', 'Defense_AST_Home', 'Defense_STL_Home',\n",
       "       'Defense_BLK_Home', 'Defense_PF_Home', 'Defense_PTS_Home'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50e51d45-7d9f-422e-a403-47a741b21f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_56268\\1740641694.py:35: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Visitor'] = df['Visitor'].replace(team_mapping)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_56268\\1740641694.py:36: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Home'] = df['Home'].replace(team_mapping)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_56268\\1740641694.py:37: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Defense_Team_Visitor'] = df['Defense_Team_Visitor'].replace(team_mapping)\n",
      "C:\\Users\\Joshua\\AppData\\Local\\Temp\\ipykernel_56268\\1740641694.py:38: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df['Defense_Team_Home'] = df['Defense_Team_Home'].replace(team_mapping)\n"
     ]
    }
   ],
   "source": [
    "#encoding teams\n",
    "team_mapping = {\n",
    "    'BOS': 0,\n",
    "    'NYK': 1,\n",
    "    'MIL': 2,\n",
    "    'CLE': 3,\n",
    "    'ORL': 4,\n",
    "    'IND': 5,\n",
    "    'PHI': 6,\n",
    "    'MIA': 7,\n",
    "    'CHI': 8,\n",
    "    'ATL': 9,\n",
    "    'BRK': 10,\n",
    "    'TOR': 11,\n",
    "    'CHO': 12,\n",
    "    'WAS': 13,\n",
    "    'DET': 14,\n",
    "    'OKC': 15,\n",
    "    'DEN': 16,\n",
    "    'MIN': 17,\n",
    "    'LAC': 18,\n",
    "    'DAL': 19,\n",
    "    'PHO': 20,\n",
    "    'NOP': 21,\n",
    "    'LAL': 22,\n",
    "    'SAC': 23,\n",
    "    'GSW': 24,\n",
    "    'HOU': 25,\n",
    "    'UTA': 26,\n",
    "    'MEM': 27,\n",
    "    'SAS': 28,\n",
    "    'POR': 29\n",
    "}\n",
    "# Replace 'Visitor' and 'Home' columns using the mapping\n",
    "df['Visitor'] = df['Visitor'].replace(team_mapping)\n",
    "df['Home'] = df['Home'].replace(team_mapping)\n",
    "df['Defense_Team_Visitor'] = df['Defense_Team_Visitor'].replace(team_mapping)\n",
    "df['Defense_Team_Home'] = df['Defense_Team_Home'].replace(team_mapping)\n",
    "\n",
    "# Display the updated DataFrame\n",
    "df2=df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c1595db0-eafb-45ff-8690-3ff48113636f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8,  9, 24,  4,  0, 11, 10,  7, 14, 15,  2, 25, 27, 29, 20, 23, 22,\n",
       "        5,  1, 18,  3,  6, 28, 16, 13, 21, 12, 17, 19, 26], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_values=df2['Home'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ab86c21-9342-4dcd-bf79-2657b191ccd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n",
      "\n",
      "[9550 rows x 0 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find all columns that contain strings (object type)\n",
    "string_columns = df2.select_dtypes(include=['object'])\n",
    "\n",
    "# Display those columns\n",
    "print(string_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b5b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2622fc02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.rename(columns={\n",
    "    'Offense_FG%_Visitor': 'Visitor_offense_FG%',\n",
    "    'Offense_2P%_Visitor': 'Visitor_offense_2P%',\n",
    "    'Offense_PTS_Visitor': 'Visitor_offense_PTS',\n",
    "    'Offense_FG_Visitor': 'Visitor_offense_FG',\n",
    "    'Offense_3P%_Visitor': 'Visitor_offense_3P%',\n",
    "    'Defense_FG%_Visitor': 'Visitor_defense_FG%',\n",
    "    'Visitor': 'Visitor_offense_Team',\n",
    "    'Defense_FG%_Home': 'Home_defense_FG%',\n",
    "    'Defense_TRB_Home': 'Home_defense_TRB',\n",
    "    'Defense_2P%_Home': 'Home_defense_2P%',\n",
    "    'Defense_AST_Home': 'Home_defense_AST',\n",
    "    'Defense_BLK_Home': 'Home_defense_BLK',\n",
    "    'Home': 'Home_offense_Team',\n",
    "    'Offense_FG%_Home': 'Home_offense_FG%',\n",
    "    'Offense_3P%_Home': 'Home_offense_3P%',\n",
    "    'Defense_FG_Home': 'Home_defense_FG',\n",
    "    'Defense_PTS_Home': 'Home_defense_PTS',\n",
    "    'Decimal_Visitor': 'away_team_odds',\n",
    "    'Home_Decimal': 'home_team_odds'})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "756cb7ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Visitor_offense_Team</th>\n",
       "      <th>away_team_odds</th>\n",
       "      <th>Home_offense_Team</th>\n",
       "      <th>home_team_odds</th>\n",
       "      <th>Season</th>\n",
       "      <th>Home_Winner</th>\n",
       "      <th>Offense_MP_Visitor</th>\n",
       "      <th>Visitor_offense_FG</th>\n",
       "      <th>Offense_FGA_Visitor</th>\n",
       "      <th>Visitor_offense_FG%</th>\n",
       "      <th>Offense_3P_Visitor</th>\n",
       "      <th>Offense_3PA_Visitor</th>\n",
       "      <th>Visitor_offense_3P%</th>\n",
       "      <th>Offense_2P_Visitor</th>\n",
       "      <th>Offense_2PA_Visitor</th>\n",
       "      <th>Visitor_offense_2P%</th>\n",
       "      <th>Offense_FT_Visitor</th>\n",
       "      <th>Offense_FTA_Visitor</th>\n",
       "      <th>Offense_FT%_Visitor</th>\n",
       "      <th>Offense_ORB_Visitor</th>\n",
       "      <th>Offense_DRB_Visitor</th>\n",
       "      <th>Offense_TRB_Visitor</th>\n",
       "      <th>Offense_AST_Visitor</th>\n",
       "      <th>Offense_STL_Visitor</th>\n",
       "      <th>Offense_BLK_Visitor</th>\n",
       "      <th>Offense_PF_Visitor</th>\n",
       "      <th>Visitor_offense_PTS</th>\n",
       "      <th>Defense_Team_Visitor</th>\n",
       "      <th>Defense_MP_Visitor</th>\n",
       "      <th>Defense_FG_Visitor</th>\n",
       "      <th>Defense_FGA_Visitor</th>\n",
       "      <th>Visitor_defense_FG%</th>\n",
       "      <th>Defense_3P_Visitor</th>\n",
       "      <th>Defense_3PA_Visitor</th>\n",
       "      <th>Defense_3P%_Visitor</th>\n",
       "      <th>Defense_2P_Visitor</th>\n",
       "      <th>Defense_2PA_Visitor</th>\n",
       "      <th>Defense_2P%_Visitor</th>\n",
       "      <th>Defense_FT_Visitor</th>\n",
       "      <th>Defense_FTA_Visitor</th>\n",
       "      <th>Defense_FT%_Visitor</th>\n",
       "      <th>Defense_ORB_Visitor</th>\n",
       "      <th>Defense_DRB_Visitor</th>\n",
       "      <th>Defense_TRB_Visitor</th>\n",
       "      <th>Defense_AST_Visitor</th>\n",
       "      <th>Defense_STL_Visitor</th>\n",
       "      <th>Defense_BLK_Visitor</th>\n",
       "      <th>Defense_PF_Visitor</th>\n",
       "      <th>Defense_PTS_Visitor</th>\n",
       "      <th>Offense_MP_Home</th>\n",
       "      <th>Offense_FG_Home</th>\n",
       "      <th>Offense_FGA_Home</th>\n",
       "      <th>Home_offense_FG%</th>\n",
       "      <th>Offense_3P_Home</th>\n",
       "      <th>Offense_3PA_Home</th>\n",
       "      <th>Home_offense_3P%</th>\n",
       "      <th>Offense_2P_Home</th>\n",
       "      <th>Offense_2PA_Home</th>\n",
       "      <th>Offense_2P%_Home</th>\n",
       "      <th>Offense_FT_Home</th>\n",
       "      <th>Offense_FTA_Home</th>\n",
       "      <th>Offense_FT%_Home</th>\n",
       "      <th>Offense_ORB_Home</th>\n",
       "      <th>Offense_DRB_Home</th>\n",
       "      <th>Offense_TRB_Home</th>\n",
       "      <th>Offense_AST_Home</th>\n",
       "      <th>Offense_STL_Home</th>\n",
       "      <th>Offense_BLK_Home</th>\n",
       "      <th>Offense_PF_Home</th>\n",
       "      <th>Offense_PTS_Home</th>\n",
       "      <th>Defense_Team_Home</th>\n",
       "      <th>Defense_MP_Home</th>\n",
       "      <th>Home_defense_FG</th>\n",
       "      <th>Defense_FGA_Home</th>\n",
       "      <th>Home_defense_FG%</th>\n",
       "      <th>Defense_3P_Home</th>\n",
       "      <th>Defense_3PA_Home</th>\n",
       "      <th>Defense_3P%_Home</th>\n",
       "      <th>Defense_2P_Home</th>\n",
       "      <th>Defense_2PA_Home</th>\n",
       "      <th>Home_defense_2P%</th>\n",
       "      <th>Defense_FT_Home</th>\n",
       "      <th>Defense_FTA_Home</th>\n",
       "      <th>Defense_FT%_Home</th>\n",
       "      <th>Defense_ORB_Home</th>\n",
       "      <th>Defense_DRB_Home</th>\n",
       "      <th>Home_defense_TRB</th>\n",
       "      <th>Home_defense_AST</th>\n",
       "      <th>Defense_STL_Home</th>\n",
       "      <th>Home_defense_BLK</th>\n",
       "      <th>Defense_PF_Home</th>\n",
       "      <th>Home_defense_PTS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>8</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>241.2</td>\n",
       "      <td>37.7</td>\n",
       "      <td>82.2</td>\n",
       "      <td>0.458</td>\n",
       "      <td>10.1</td>\n",
       "      <td>27.5</td>\n",
       "      <td>0.367</td>\n",
       "      <td>27.6</td>\n",
       "      <td>54.7</td>\n",
       "      <td>0.504</td>\n",
       "      <td>17.7</td>\n",
       "      <td>23.6</td>\n",
       "      <td>0.751</td>\n",
       "      <td>11.1</td>\n",
       "      <td>31.9</td>\n",
       "      <td>43.0</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.1</td>\n",
       "      <td>18.4</td>\n",
       "      <td>103.1</td>\n",
       "      <td>3</td>\n",
       "      <td>241.2</td>\n",
       "      <td>38.1</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0.456</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.343</td>\n",
       "      <td>30.3</td>\n",
       "      <td>61.0</td>\n",
       "      <td>0.497</td>\n",
       "      <td>14.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.745</td>\n",
       "      <td>10.8</td>\n",
       "      <td>30.3</td>\n",
       "      <td>41.1</td>\n",
       "      <td>24.1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>20.5</td>\n",
       "      <td>98.7</td>\n",
       "      <td>242.4</td>\n",
       "      <td>36.6</td>\n",
       "      <td>82.9</td>\n",
       "      <td>0.442</td>\n",
       "      <td>7.9</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.353</td>\n",
       "      <td>28.7</td>\n",
       "      <td>60.6</td>\n",
       "      <td>0.474</td>\n",
       "      <td>19.7</td>\n",
       "      <td>25.2</td>\n",
       "      <td>0.783</td>\n",
       "      <td>11.7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>45.7</td>\n",
       "      <td>21.7</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.8</td>\n",
       "      <td>18.2</td>\n",
       "      <td>100.8</td>\n",
       "      <td>8</td>\n",
       "      <td>242.4</td>\n",
       "      <td>37.7</td>\n",
       "      <td>86.7</td>\n",
       "      <td>0.435</td>\n",
       "      <td>6.6</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.335</td>\n",
       "      <td>31.2</td>\n",
       "      <td>67.1</td>\n",
       "      <td>0.465</td>\n",
       "      <td>15.7</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.749</td>\n",
       "      <td>11.7</td>\n",
       "      <td>31.7</td>\n",
       "      <td>43.4</td>\n",
       "      <td>20.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>5.4</td>\n",
       "      <td>21.2</td>\n",
       "      <td>97.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>3.550000</td>\n",
       "      <td>9</td>\n",
       "      <td>1.312500</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>241.8</td>\n",
       "      <td>37.1</td>\n",
       "      <td>85.8</td>\n",
       "      <td>0.432</td>\n",
       "      <td>8.6</td>\n",
       "      <td>24.9</td>\n",
       "      <td>0.344</td>\n",
       "      <td>28.5</td>\n",
       "      <td>60.9</td>\n",
       "      <td>0.468</td>\n",
       "      <td>15.8</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.703</td>\n",
       "      <td>12.8</td>\n",
       "      <td>32.1</td>\n",
       "      <td>44.9</td>\n",
       "      <td>21.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>4.7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>98.5</td>\n",
       "      <td>14</td>\n",
       "      <td>241.8</td>\n",
       "      <td>37.9</td>\n",
       "      <td>83.1</td>\n",
       "      <td>0.456</td>\n",
       "      <td>7.7</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.355</td>\n",
       "      <td>30.1</td>\n",
       "      <td>61.3</td>\n",
       "      <td>0.491</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.772</td>\n",
       "      <td>10.7</td>\n",
       "      <td>33.4</td>\n",
       "      <td>44.1</td>\n",
       "      <td>23.8</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>19.3</td>\n",
       "      <td>99.5</td>\n",
       "      <td>240.6</td>\n",
       "      <td>38.1</td>\n",
       "      <td>81.7</td>\n",
       "      <td>0.466</td>\n",
       "      <td>10.0</td>\n",
       "      <td>26.2</td>\n",
       "      <td>0.380</td>\n",
       "      <td>28.1</td>\n",
       "      <td>55.5</td>\n",
       "      <td>0.506</td>\n",
       "      <td>16.5</td>\n",
       "      <td>21.2</td>\n",
       "      <td>0.778</td>\n",
       "      <td>8.7</td>\n",
       "      <td>31.8</td>\n",
       "      <td>40.6</td>\n",
       "      <td>25.7</td>\n",
       "      <td>9.1</td>\n",
       "      <td>4.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>102.5</td>\n",
       "      <td>9</td>\n",
       "      <td>240.6</td>\n",
       "      <td>36.5</td>\n",
       "      <td>83.1</td>\n",
       "      <td>0.439</td>\n",
       "      <td>8.8</td>\n",
       "      <td>25.8</td>\n",
       "      <td>0.341</td>\n",
       "      <td>27.7</td>\n",
       "      <td>57.4</td>\n",
       "      <td>0.483</td>\n",
       "      <td>15.4</td>\n",
       "      <td>20.1</td>\n",
       "      <td>0.764</td>\n",
       "      <td>11.6</td>\n",
       "      <td>32.1</td>\n",
       "      <td>43.6</td>\n",
       "      <td>23.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.9</td>\n",
       "      <td>19.6</td>\n",
       "      <td>97.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>24</td>\n",
       "      <td>1.140845</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>241.2</td>\n",
       "      <td>37.9</td>\n",
       "      <td>82.9</td>\n",
       "      <td>0.457</td>\n",
       "      <td>7.1</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.370</td>\n",
       "      <td>30.8</td>\n",
       "      <td>63.6</td>\n",
       "      <td>0.484</td>\n",
       "      <td>16.4</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.751</td>\n",
       "      <td>11.5</td>\n",
       "      <td>32.0</td>\n",
       "      <td>43.5</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>6.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>99.4</td>\n",
       "      <td>21</td>\n",
       "      <td>241.2</td>\n",
       "      <td>37.9</td>\n",
       "      <td>83.1</td>\n",
       "      <td>0.456</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>0.335</td>\n",
       "      <td>31.4</td>\n",
       "      <td>63.5</td>\n",
       "      <td>0.494</td>\n",
       "      <td>16.2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.759</td>\n",
       "      <td>10.6</td>\n",
       "      <td>30.9</td>\n",
       "      <td>41.5</td>\n",
       "      <td>20.7</td>\n",
       "      <td>6.8</td>\n",
       "      <td>5.8</td>\n",
       "      <td>18.7</td>\n",
       "      <td>98.6</td>\n",
       "      <td>240.6</td>\n",
       "      <td>41.6</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.478</td>\n",
       "      <td>10.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.398</td>\n",
       "      <td>30.8</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.514</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20.8</td>\n",
       "      <td>0.768</td>\n",
       "      <td>10.4</td>\n",
       "      <td>34.3</td>\n",
       "      <td>44.7</td>\n",
       "      <td>27.4</td>\n",
       "      <td>9.3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.9</td>\n",
       "      <td>110.0</td>\n",
       "      <td>24</td>\n",
       "      <td>240.6</td>\n",
       "      <td>37.0</td>\n",
       "      <td>86.4</td>\n",
       "      <td>0.428</td>\n",
       "      <td>7.2</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.337</td>\n",
       "      <td>29.7</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>18.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.763</td>\n",
       "      <td>11.7</td>\n",
       "      <td>32.8</td>\n",
       "      <td>44.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>3.6</td>\n",
       "      <td>18.8</td>\n",
       "      <td>99.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>1.555556</td>\n",
       "      <td>4</td>\n",
       "      <td>2.600000</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>38.3</td>\n",
       "      <td>82.8</td>\n",
       "      <td>0.462</td>\n",
       "      <td>6.1</td>\n",
       "      <td>16.8</td>\n",
       "      <td>0.360</td>\n",
       "      <td>32.2</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.488</td>\n",
       "      <td>15.9</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.742</td>\n",
       "      <td>10.5</td>\n",
       "      <td>34.2</td>\n",
       "      <td>44.7</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.6</td>\n",
       "      <td>20.8</td>\n",
       "      <td>98.5</td>\n",
       "      <td>13</td>\n",
       "      <td>243.4</td>\n",
       "      <td>36.2</td>\n",
       "      <td>83.5</td>\n",
       "      <td>0.433</td>\n",
       "      <td>8.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.349</td>\n",
       "      <td>28.1</td>\n",
       "      <td>60.5</td>\n",
       "      <td>0.465</td>\n",
       "      <td>17.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.738</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.7</td>\n",
       "      <td>41.7</td>\n",
       "      <td>19.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>19.6</td>\n",
       "      <td>97.8</td>\n",
       "      <td>240.9</td>\n",
       "      <td>37.5</td>\n",
       "      <td>82.8</td>\n",
       "      <td>0.453</td>\n",
       "      <td>6.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0.347</td>\n",
       "      <td>30.8</td>\n",
       "      <td>63.3</td>\n",
       "      <td>0.486</td>\n",
       "      <td>13.9</td>\n",
       "      <td>19.1</td>\n",
       "      <td>0.729</td>\n",
       "      <td>10.0</td>\n",
       "      <td>31.8</td>\n",
       "      <td>41.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>95.7</td>\n",
       "      <td>4</td>\n",
       "      <td>240.9</td>\n",
       "      <td>38.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>8.3</td>\n",
       "      <td>22.6</td>\n",
       "      <td>0.368</td>\n",
       "      <td>29.6</td>\n",
       "      <td>59.4</td>\n",
       "      <td>0.499</td>\n",
       "      <td>17.2</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.751</td>\n",
       "      <td>10.1</td>\n",
       "      <td>33.4</td>\n",
       "      <td>43.5</td>\n",
       "      <td>23.4</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5.4</td>\n",
       "      <td>17.9</td>\n",
       "      <td>101.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1.076923</td>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>241.5</td>\n",
       "      <td>33.7</td>\n",
       "      <td>82.6</td>\n",
       "      <td>0.408</td>\n",
       "      <td>8.4</td>\n",
       "      <td>26.3</td>\n",
       "      <td>0.320</td>\n",
       "      <td>25.3</td>\n",
       "      <td>56.3</td>\n",
       "      <td>0.449</td>\n",
       "      <td>16.1</td>\n",
       "      <td>23.8</td>\n",
       "      <td>0.676</td>\n",
       "      <td>11.9</td>\n",
       "      <td>30.9</td>\n",
       "      <td>42.9</td>\n",
       "      <td>20.5</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5.9</td>\n",
       "      <td>21.7</td>\n",
       "      <td>92.0</td>\n",
       "      <td>6</td>\n",
       "      <td>241.5</td>\n",
       "      <td>37.1</td>\n",
       "      <td>82.7</td>\n",
       "      <td>0.449</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.350</td>\n",
       "      <td>29.1</td>\n",
       "      <td>59.8</td>\n",
       "      <td>0.487</td>\n",
       "      <td>18.7</td>\n",
       "      <td>24.7</td>\n",
       "      <td>0.756</td>\n",
       "      <td>11.5</td>\n",
       "      <td>34.8</td>\n",
       "      <td>46.3</td>\n",
       "      <td>23.7</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>20.2</td>\n",
       "      <td>101.0</td>\n",
       "      <td>242.4</td>\n",
       "      <td>38.9</td>\n",
       "      <td>87.9</td>\n",
       "      <td>0.443</td>\n",
       "      <td>8.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>0.327</td>\n",
       "      <td>30.9</td>\n",
       "      <td>63.3</td>\n",
       "      <td>0.488</td>\n",
       "      <td>15.4</td>\n",
       "      <td>20.5</td>\n",
       "      <td>0.754</td>\n",
       "      <td>11.1</td>\n",
       "      <td>32.7</td>\n",
       "      <td>43.8</td>\n",
       "      <td>24.5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>21.2</td>\n",
       "      <td>101.4</td>\n",
       "      <td>0</td>\n",
       "      <td>242.4</td>\n",
       "      <td>38.1</td>\n",
       "      <td>84.7</td>\n",
       "      <td>0.450</td>\n",
       "      <td>7.4</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.336</td>\n",
       "      <td>30.7</td>\n",
       "      <td>62.7</td>\n",
       "      <td>0.490</td>\n",
       "      <td>17.6</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.755</td>\n",
       "      <td>10.9</td>\n",
       "      <td>33.8</td>\n",
       "      <td>44.7</td>\n",
       "      <td>21.9</td>\n",
       "      <td>7.1</td>\n",
       "      <td>5.3</td>\n",
       "      <td>18.8</td>\n",
       "      <td>101.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9545</th>\n",
       "      <td>24</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>13</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>240.6</td>\n",
       "      <td>40.5</td>\n",
       "      <td>86.4</td>\n",
       "      <td>0.469</td>\n",
       "      <td>14.3</td>\n",
       "      <td>39.4</td>\n",
       "      <td>0.364</td>\n",
       "      <td>26.2</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0.557</td>\n",
       "      <td>15.6</td>\n",
       "      <td>20.3</td>\n",
       "      <td>0.769</td>\n",
       "      <td>9.8</td>\n",
       "      <td>35.7</td>\n",
       "      <td>45.5</td>\n",
       "      <td>27.1</td>\n",
       "      <td>8.8</td>\n",
       "      <td>4.5</td>\n",
       "      <td>21.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>24</td>\n",
       "      <td>240.6</td>\n",
       "      <td>37.9</td>\n",
       "      <td>86.6</td>\n",
       "      <td>0.438</td>\n",
       "      <td>12.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.339</td>\n",
       "      <td>25.7</td>\n",
       "      <td>50.6</td>\n",
       "      <td>0.509</td>\n",
       "      <td>17.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.759</td>\n",
       "      <td>9.7</td>\n",
       "      <td>33.0</td>\n",
       "      <td>42.6</td>\n",
       "      <td>22.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>18.0</td>\n",
       "      <td>105.5</td>\n",
       "      <td>241.8</td>\n",
       "      <td>40.6</td>\n",
       "      <td>86.0</td>\n",
       "      <td>0.472</td>\n",
       "      <td>10.5</td>\n",
       "      <td>30.6</td>\n",
       "      <td>0.342</td>\n",
       "      <td>30.1</td>\n",
       "      <td>55.4</td>\n",
       "      <td>0.543</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>0.783</td>\n",
       "      <td>9.0</td>\n",
       "      <td>34.1</td>\n",
       "      <td>43.1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6.4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>108.6</td>\n",
       "      <td>13</td>\n",
       "      <td>241.8</td>\n",
       "      <td>41.3</td>\n",
       "      <td>88.9</td>\n",
       "      <td>0.464</td>\n",
       "      <td>11.5</td>\n",
       "      <td>31.8</td>\n",
       "      <td>0.361</td>\n",
       "      <td>29.8</td>\n",
       "      <td>57.1</td>\n",
       "      <td>0.522</td>\n",
       "      <td>18.0</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.807</td>\n",
       "      <td>10.2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>44.2</td>\n",
       "      <td>23.7</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.2</td>\n",
       "      <td>19.9</td>\n",
       "      <td>112.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9546</th>\n",
       "      <td>7</td>\n",
       "      <td>1.952381</td>\n",
       "      <td>9</td>\n",
       "      <td>1.869565</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>242.1</td>\n",
       "      <td>39.6</td>\n",
       "      <td>84.8</td>\n",
       "      <td>0.467</td>\n",
       "      <td>13.6</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.379</td>\n",
       "      <td>26.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.531</td>\n",
       "      <td>17.3</td>\n",
       "      <td>21.4</td>\n",
       "      <td>0.808</td>\n",
       "      <td>9.8</td>\n",
       "      <td>33.9</td>\n",
       "      <td>43.7</td>\n",
       "      <td>25.5</td>\n",
       "      <td>7.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>20.5</td>\n",
       "      <td>110.0</td>\n",
       "      <td>7</td>\n",
       "      <td>242.1</td>\n",
       "      <td>37.5</td>\n",
       "      <td>84.0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>13.0</td>\n",
       "      <td>38.3</td>\n",
       "      <td>0.339</td>\n",
       "      <td>24.6</td>\n",
       "      <td>45.7</td>\n",
       "      <td>0.537</td>\n",
       "      <td>17.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>0.779</td>\n",
       "      <td>9.5</td>\n",
       "      <td>32.1</td>\n",
       "      <td>41.7</td>\n",
       "      <td>23.3</td>\n",
       "      <td>7.4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>20.6</td>\n",
       "      <td>105.6</td>\n",
       "      <td>240.3</td>\n",
       "      <td>41.5</td>\n",
       "      <td>88.3</td>\n",
       "      <td>0.470</td>\n",
       "      <td>12.9</td>\n",
       "      <td>34.4</td>\n",
       "      <td>0.374</td>\n",
       "      <td>28.6</td>\n",
       "      <td>53.9</td>\n",
       "      <td>0.531</td>\n",
       "      <td>18.1</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.812</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>18.7</td>\n",
       "      <td>113.9</td>\n",
       "      <td>9</td>\n",
       "      <td>240.3</td>\n",
       "      <td>41.9</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.471</td>\n",
       "      <td>12.8</td>\n",
       "      <td>35.2</td>\n",
       "      <td>0.364</td>\n",
       "      <td>29.1</td>\n",
       "      <td>53.7</td>\n",
       "      <td>0.541</td>\n",
       "      <td>15.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.792</td>\n",
       "      <td>10.2</td>\n",
       "      <td>33.6</td>\n",
       "      <td>43.9</td>\n",
       "      <td>25.4</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>20.3</td>\n",
       "      <td>112.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9547</th>\n",
       "      <td>26</td>\n",
       "      <td>2.550000</td>\n",
       "      <td>17</td>\n",
       "      <td>1.571429</td>\n",
       "      <td>2022</td>\n",
       "      <td>0</td>\n",
       "      <td>240.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>86.2</td>\n",
       "      <td>0.471</td>\n",
       "      <td>14.5</td>\n",
       "      <td>40.3</td>\n",
       "      <td>0.360</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.8</td>\n",
       "      <td>0.568</td>\n",
       "      <td>17.9</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.767</td>\n",
       "      <td>10.8</td>\n",
       "      <td>35.6</td>\n",
       "      <td>46.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>18.9</td>\n",
       "      <td>113.6</td>\n",
       "      <td>26</td>\n",
       "      <td>240.6</td>\n",
       "      <td>40.4</td>\n",
       "      <td>89.2</td>\n",
       "      <td>0.453</td>\n",
       "      <td>12.1</td>\n",
       "      <td>34.6</td>\n",
       "      <td>0.350</td>\n",
       "      <td>28.3</td>\n",
       "      <td>54.6</td>\n",
       "      <td>0.518</td>\n",
       "      <td>14.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>0.758</td>\n",
       "      <td>9.9</td>\n",
       "      <td>31.7</td>\n",
       "      <td>41.6</td>\n",
       "      <td>23.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>4.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>107.6</td>\n",
       "      <td>241.2</td>\n",
       "      <td>41.6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.457</td>\n",
       "      <td>14.8</td>\n",
       "      <td>41.3</td>\n",
       "      <td>0.358</td>\n",
       "      <td>26.8</td>\n",
       "      <td>49.7</td>\n",
       "      <td>0.540</td>\n",
       "      <td>18.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.778</td>\n",
       "      <td>11.2</td>\n",
       "      <td>32.9</td>\n",
       "      <td>44.2</td>\n",
       "      <td>25.7</td>\n",
       "      <td>8.8</td>\n",
       "      <td>5.6</td>\n",
       "      <td>21.8</td>\n",
       "      <td>115.9</td>\n",
       "      <td>17</td>\n",
       "      <td>241.2</td>\n",
       "      <td>40.2</td>\n",
       "      <td>87.4</td>\n",
       "      <td>0.460</td>\n",
       "      <td>13.1</td>\n",
       "      <td>37.3</td>\n",
       "      <td>0.350</td>\n",
       "      <td>27.2</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.543</td>\n",
       "      <td>19.8</td>\n",
       "      <td>25.4</td>\n",
       "      <td>0.780</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.9</td>\n",
       "      <td>45.9</td>\n",
       "      <td>26.2</td>\n",
       "      <td>7.2</td>\n",
       "      <td>4.8</td>\n",
       "      <td>20.9</td>\n",
       "      <td>113.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9548</th>\n",
       "      <td>20</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>27</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>240.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>90.1</td>\n",
       "      <td>0.485</td>\n",
       "      <td>11.6</td>\n",
       "      <td>31.9</td>\n",
       "      <td>0.364</td>\n",
       "      <td>32.1</td>\n",
       "      <td>58.2</td>\n",
       "      <td>0.551</td>\n",
       "      <td>15.9</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.797</td>\n",
       "      <td>9.8</td>\n",
       "      <td>35.5</td>\n",
       "      <td>45.3</td>\n",
       "      <td>27.4</td>\n",
       "      <td>8.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>114.8</td>\n",
       "      <td>20</td>\n",
       "      <td>240.6</td>\n",
       "      <td>39.2</td>\n",
       "      <td>88.3</td>\n",
       "      <td>0.444</td>\n",
       "      <td>11.6</td>\n",
       "      <td>34.2</td>\n",
       "      <td>0.340</td>\n",
       "      <td>27.6</td>\n",
       "      <td>54.1</td>\n",
       "      <td>0.510</td>\n",
       "      <td>17.3</td>\n",
       "      <td>22.7</td>\n",
       "      <td>0.761</td>\n",
       "      <td>10.5</td>\n",
       "      <td>33.9</td>\n",
       "      <td>44.5</td>\n",
       "      <td>22.9</td>\n",
       "      <td>7.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.9</td>\n",
       "      <td>107.3</td>\n",
       "      <td>241.2</td>\n",
       "      <td>43.5</td>\n",
       "      <td>94.4</td>\n",
       "      <td>0.461</td>\n",
       "      <td>11.5</td>\n",
       "      <td>32.7</td>\n",
       "      <td>0.353</td>\n",
       "      <td>32.0</td>\n",
       "      <td>61.7</td>\n",
       "      <td>0.519</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.1</td>\n",
       "      <td>0.734</td>\n",
       "      <td>14.1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>49.2</td>\n",
       "      <td>26.0</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.5</td>\n",
       "      <td>19.8</td>\n",
       "      <td>115.6</td>\n",
       "      <td>27</td>\n",
       "      <td>241.2</td>\n",
       "      <td>40.3</td>\n",
       "      <td>88.6</td>\n",
       "      <td>0.455</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.349</td>\n",
       "      <td>28.3</td>\n",
       "      <td>54.2</td>\n",
       "      <td>0.522</td>\n",
       "      <td>17.3</td>\n",
       "      <td>22.4</td>\n",
       "      <td>0.771</td>\n",
       "      <td>10.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>109.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9549</th>\n",
       "      <td>25</td>\n",
       "      <td>3.400000</td>\n",
       "      <td>22</td>\n",
       "      <td>1.357143</td>\n",
       "      <td>2022</td>\n",
       "      <td>1</td>\n",
       "      <td>240.9</td>\n",
       "      <td>39.4</td>\n",
       "      <td>86.4</td>\n",
       "      <td>0.456</td>\n",
       "      <td>13.5</td>\n",
       "      <td>38.7</td>\n",
       "      <td>0.349</td>\n",
       "      <td>25.9</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.543</td>\n",
       "      <td>17.5</td>\n",
       "      <td>24.5</td>\n",
       "      <td>0.713</td>\n",
       "      <td>9.6</td>\n",
       "      <td>32.4</td>\n",
       "      <td>42.0</td>\n",
       "      <td>23.6</td>\n",
       "      <td>7.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>109.7</td>\n",
       "      <td>25</td>\n",
       "      <td>240.9</td>\n",
       "      <td>43.4</td>\n",
       "      <td>89.9</td>\n",
       "      <td>0.483</td>\n",
       "      <td>12.8</td>\n",
       "      <td>36.2</td>\n",
       "      <td>0.353</td>\n",
       "      <td>30.7</td>\n",
       "      <td>53.8</td>\n",
       "      <td>0.570</td>\n",
       "      <td>18.5</td>\n",
       "      <td>23.7</td>\n",
       "      <td>0.782</td>\n",
       "      <td>11.2</td>\n",
       "      <td>34.5</td>\n",
       "      <td>45.7</td>\n",
       "      <td>25.6</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>22.1</td>\n",
       "      <td>118.2</td>\n",
       "      <td>243.7</td>\n",
       "      <td>41.6</td>\n",
       "      <td>88.8</td>\n",
       "      <td>0.469</td>\n",
       "      <td>12.0</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.347</td>\n",
       "      <td>29.7</td>\n",
       "      <td>54.3</td>\n",
       "      <td>0.546</td>\n",
       "      <td>16.8</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.732</td>\n",
       "      <td>9.5</td>\n",
       "      <td>34.5</td>\n",
       "      <td>44.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>7.6</td>\n",
       "      <td>5.2</td>\n",
       "      <td>20.2</td>\n",
       "      <td>112.1</td>\n",
       "      <td>22</td>\n",
       "      <td>243.7</td>\n",
       "      <td>42.6</td>\n",
       "      <td>90.5</td>\n",
       "      <td>0.470</td>\n",
       "      <td>12.6</td>\n",
       "      <td>35.8</td>\n",
       "      <td>0.352</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.7</td>\n",
       "      <td>0.548</td>\n",
       "      <td>17.4</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.747</td>\n",
       "      <td>11.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>46.6</td>\n",
       "      <td>26.3</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>20.1</td>\n",
       "      <td>115.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9550 rows Ã— 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Visitor_offense_Team  away_team_odds  Home_offense_Team  home_team_odds  \\\n",
       "0                        3        2.600000                  8        1.555556   \n",
       "1                       14        3.550000                  9        1.312500   \n",
       "2                       21        6.100000                 24        1.140845   \n",
       "3                       13        1.555556                  4        2.600000   \n",
       "4                        6        9.000000                  0        1.076923   \n",
       "...                    ...             ...                ...             ...   \n",
       "9545                    24        1.714286                 13        2.200000   \n",
       "9546                     7        1.952381                  9        1.869565   \n",
       "9547                    26        2.550000                 17        1.571429   \n",
       "9548                    20        6.500000                 27        1.125000   \n",
       "9549                    25        3.400000                 22        1.357143   \n",
       "\n",
       "      Season  Home_Winner  Offense_MP_Visitor  Visitor_offense_FG  \\\n",
       "0       2015            1               241.2                37.7   \n",
       "1       2015            0               241.8                37.1   \n",
       "2       2015            1               241.2                37.9   \n",
       "3       2015            0               243.4                38.3   \n",
       "4       2015            1               241.5                33.7   \n",
       "...      ...          ...                 ...                 ...   \n",
       "9545    2022            0               240.6                40.5   \n",
       "9546    2022            1               242.1                39.6   \n",
       "9547    2022            0               240.6                40.6   \n",
       "9548    2022            1               240.6                43.7   \n",
       "9549    2022            1               240.9                39.4   \n",
       "\n",
       "      Offense_FGA_Visitor  Visitor_offense_FG%  Offense_3P_Visitor  \\\n",
       "0                    82.2                0.458                10.1   \n",
       "1                    85.8                0.432                 8.6   \n",
       "2                    82.9                0.457                 7.1   \n",
       "3                    82.8                0.462                 6.1   \n",
       "4                    82.6                0.408                 8.4   \n",
       "...                   ...                  ...                 ...   \n",
       "9545                 86.4                0.469                14.3   \n",
       "9546                 84.8                0.467                13.6   \n",
       "9547                 86.2                0.471                14.5   \n",
       "9548                 90.1                0.485                11.6   \n",
       "9549                 86.4                0.456                13.5   \n",
       "\n",
       "      Offense_3PA_Visitor  Visitor_offense_3P%  Offense_2P_Visitor  \\\n",
       "0                    27.5                0.367                27.6   \n",
       "1                    24.9                0.344                28.5   \n",
       "2                    19.3                0.370                30.8   \n",
       "3                    16.8                0.360                32.2   \n",
       "4                    26.3                0.320                25.3   \n",
       "...                   ...                  ...                 ...   \n",
       "9545                 39.4                0.364                26.2   \n",
       "9546                 35.8                0.379                26.0   \n",
       "9547                 40.3                0.360                26.0   \n",
       "9548                 31.9                0.364                32.1   \n",
       "9549                 38.7                0.349                25.9   \n",
       "\n",
       "      Offense_2PA_Visitor  Visitor_offense_2P%  Offense_FT_Visitor  \\\n",
       "0                    54.7                0.504                17.7   \n",
       "1                    60.9                0.468                15.8   \n",
       "2                    63.6                0.484                16.4   \n",
       "3                    66.0                0.488                15.9   \n",
       "4                    56.3                0.449                16.1   \n",
       "...                   ...                  ...                 ...   \n",
       "9545                 47.0                0.557                15.6   \n",
       "9546                 49.0                0.531                17.3   \n",
       "9547                 45.8                0.568                17.9   \n",
       "9548                 58.2                0.551                15.9   \n",
       "9549                 47.7                0.543                17.5   \n",
       "\n",
       "      Offense_FTA_Visitor  Offense_FT%_Visitor  Offense_ORB_Visitor  \\\n",
       "0                    23.6                0.751                 11.1   \n",
       "1                    22.4                0.703                 12.8   \n",
       "2                    21.8                0.751                 11.5   \n",
       "3                    21.4                0.742                 10.5   \n",
       "4                    23.8                0.676                 11.9   \n",
       "...                   ...                  ...                  ...   \n",
       "9545                 20.3                0.769                  9.8   \n",
       "9546                 21.4                0.808                  9.8   \n",
       "9547                 23.4                0.767                 10.8   \n",
       "9548                 19.9                0.797                  9.8   \n",
       "9549                 24.5                0.713                  9.6   \n",
       "\n",
       "      Offense_DRB_Visitor  Offense_TRB_Visitor  Offense_AST_Visitor  \\\n",
       "0                    31.9                 43.0                 22.1   \n",
       "1                    32.1                 44.9                 21.6   \n",
       "2                    32.0                 43.5                 22.0   \n",
       "3                    34.2                 44.7                 24.0   \n",
       "4                    30.9                 42.9                 20.5   \n",
       "...                   ...                  ...                  ...   \n",
       "9545                 35.7                 45.5                 27.1   \n",
       "9546                 33.9                 43.7                 25.5   \n",
       "9547                 35.6                 46.3                 22.4   \n",
       "9548                 35.5                 45.3                 27.4   \n",
       "9549                 32.4                 42.0                 23.6   \n",
       "\n",
       "      Offense_STL_Visitor  Offense_BLK_Visitor  Offense_PF_Visitor  \\\n",
       "0                     7.4                  4.1                18.4   \n",
       "1                     7.6                  4.7                19.0   \n",
       "2                     6.7                  6.2                18.7   \n",
       "3                     7.3                  4.6                20.8   \n",
       "4                     9.6                  5.9                21.7   \n",
       "...                   ...                  ...                 ...   \n",
       "9545                  8.8                  4.5                21.0   \n",
       "9546                  7.4                  3.2                20.5   \n",
       "9547                  7.2                  4.9                18.9   \n",
       "9548                  8.6                  4.4                19.9   \n",
       "9549                  7.3                  4.7                20.6   \n",
       "\n",
       "      Visitor_offense_PTS  Defense_Team_Visitor  Defense_MP_Visitor  \\\n",
       "0                   103.1                     3               241.2   \n",
       "1                    98.5                    14               241.8   \n",
       "2                    99.4                    21               241.2   \n",
       "3                    98.5                    13               243.4   \n",
       "4                    92.0                     6               241.5   \n",
       "...                   ...                   ...                 ...   \n",
       "9545                111.0                    24               240.6   \n",
       "9546                110.0                     7               242.1   \n",
       "9547                113.6                    26               240.6   \n",
       "9548                114.8                    20               240.6   \n",
       "9549                109.7                    25               240.9   \n",
       "\n",
       "      Defense_FG_Visitor  Defense_FGA_Visitor  Visitor_defense_FG%  \\\n",
       "0                   38.1                 83.5                0.456   \n",
       "1                   37.9                 83.1                0.456   \n",
       "2                   37.9                 83.1                0.456   \n",
       "3                   36.2                 83.5                0.433   \n",
       "4                   37.1                 82.7                0.449   \n",
       "...                  ...                  ...                  ...   \n",
       "9545                37.9                 86.6                0.438   \n",
       "9546                37.5                 84.0                0.447   \n",
       "9547                40.4                 89.2                0.453   \n",
       "9548                39.2                 88.3                0.444   \n",
       "9549                43.4                 89.9                0.483   \n",
       "\n",
       "      Defense_3P_Visitor  Defense_3PA_Visitor  Defense_3P%_Visitor  \\\n",
       "0                    7.7                 22.5                0.343   \n",
       "1                    7.7                 21.8                0.355   \n",
       "2                    6.5                 19.6                0.335   \n",
       "3                    8.0                 23.0                0.349   \n",
       "4                    8.0                 22.9                0.350   \n",
       "...                  ...                  ...                  ...   \n",
       "9545                12.2                 36.0                0.339   \n",
       "9546                13.0                 38.3                0.339   \n",
       "9547                12.1                 34.6                0.350   \n",
       "9548                11.6                 34.2                0.340   \n",
       "9549                12.8                 36.2                0.353   \n",
       "\n",
       "      Defense_2P_Visitor  Defense_2PA_Visitor  Defense_2P%_Visitor  \\\n",
       "0                   30.3                 61.0                0.497   \n",
       "1                   30.1                 61.3                0.491   \n",
       "2                   31.4                 63.5                0.494   \n",
       "3                   28.1                 60.5                0.465   \n",
       "4                   29.1                 59.8                0.487   \n",
       "...                  ...                  ...                  ...   \n",
       "9545                25.7                 50.6                0.509   \n",
       "9546                24.6                 45.7                0.537   \n",
       "9547                28.3                 54.6                0.518   \n",
       "9548                27.6                 54.1                0.510   \n",
       "9549                30.7                 53.8                0.570   \n",
       "\n",
       "      Defense_FT_Visitor  Defense_FTA_Visitor  Defense_FT%_Visitor  \\\n",
       "0                   14.8                 19.9                0.745   \n",
       "1                   16.0                 20.7                0.772   \n",
       "2                   16.2                 21.4                0.759   \n",
       "3                   17.5                 23.7                0.738   \n",
       "4                   18.7                 24.7                0.756   \n",
       "...                  ...                  ...                  ...   \n",
       "9545                17.4                 22.9                0.759   \n",
       "9546                17.5                 22.5                0.779   \n",
       "9547                14.6                 19.3                0.758   \n",
       "9548                17.3                 22.7                0.761   \n",
       "9549                18.5                 23.7                0.782   \n",
       "\n",
       "      Defense_ORB_Visitor  Defense_DRB_Visitor  Defense_TRB_Visitor  \\\n",
       "0                    10.8                 30.3                 41.1   \n",
       "1                    10.7                 33.4                 44.1   \n",
       "2                    10.6                 30.9                 41.5   \n",
       "3                    10.0                 31.7                 41.7   \n",
       "4                    11.5                 34.8                 46.3   \n",
       "...                   ...                  ...                  ...   \n",
       "9545                  9.7                 33.0                 42.6   \n",
       "9546                  9.5                 32.1                 41.7   \n",
       "9547                  9.9                 31.7                 41.6   \n",
       "9548                 10.5                 33.9                 44.5   \n",
       "9549                 11.2                 34.5                 45.7   \n",
       "\n",
       "      Defense_AST_Visitor  Defense_STL_Visitor  Defense_BLK_Visitor  \\\n",
       "0                    24.1                  7.8                  4.5   \n",
       "1                    23.8                  7.0                  4.8   \n",
       "2                    20.7                  6.8                  5.8   \n",
       "3                    19.9                  8.0                  4.3   \n",
       "4                    23.7                  9.5                  5.5   \n",
       "...                   ...                  ...                  ...   \n",
       "9545                 22.9                  7.9                  3.9   \n",
       "9546                 23.3                  7.4                  4.0   \n",
       "9547                 23.4                  7.8                  4.3   \n",
       "9548                 22.9                  7.5                  4.0   \n",
       "9549                 25.6                  9.5                  5.8   \n",
       "\n",
       "      Defense_PF_Visitor  Defense_PTS_Visitor  Offense_MP_Home  \\\n",
       "0                   20.5                 98.7            242.4   \n",
       "1                   19.3                 99.5            240.6   \n",
       "2                   18.7                 98.6            240.6   \n",
       "3                   19.6                 97.8            240.9   \n",
       "4                   20.2                101.0            242.4   \n",
       "...                  ...                  ...              ...   \n",
       "9545                18.0                105.5            241.8   \n",
       "9546                20.6                105.6            240.3   \n",
       "9547                20.3                107.6            241.2   \n",
       "9548                18.9                107.3            241.2   \n",
       "9549                22.1                118.2            243.7   \n",
       "\n",
       "      Offense_FG_Home  Offense_FGA_Home  Home_offense_FG%  Offense_3P_Home  \\\n",
       "0                36.6              82.9             0.442              7.9   \n",
       "1                38.1              81.7             0.466             10.0   \n",
       "2                41.6              87.0             0.478             10.8   \n",
       "3                37.5              82.8             0.453              6.8   \n",
       "4                38.9              87.9             0.443              8.0   \n",
       "...               ...               ...               ...              ...   \n",
       "9545             40.6              86.0             0.472             10.5   \n",
       "9546             41.5              88.3             0.470             12.9   \n",
       "9547             41.6              91.0             0.457             14.8   \n",
       "9548             43.5              94.4             0.461             11.5   \n",
       "9549             41.6              88.8             0.469             12.0   \n",
       "\n",
       "      Offense_3PA_Home  Home_offense_3P%  Offense_2P_Home  Offense_2PA_Home  \\\n",
       "0                 22.3             0.353             28.7              60.6   \n",
       "1                 26.2             0.380             28.1              55.5   \n",
       "2                 27.0             0.398             30.8              60.0   \n",
       "3                 19.5             0.347             30.8              63.3   \n",
       "4                 24.6             0.327             30.9              63.3   \n",
       "...                ...               ...              ...               ...   \n",
       "9545              30.6             0.342             30.1              55.4   \n",
       "9546              34.4             0.374             28.6              53.9   \n",
       "9547              41.3             0.358             26.8              49.7   \n",
       "9548              32.7             0.353             32.0              61.7   \n",
       "9549              34.5             0.347             29.7              54.3   \n",
       "\n",
       "      Offense_2P%_Home  Offense_FT_Home  Offense_FTA_Home  Offense_FT%_Home  \\\n",
       "0                0.474             19.7              25.2             0.783   \n",
       "1                0.506             16.5              21.2             0.778   \n",
       "2                0.514             16.0              20.8             0.768   \n",
       "3                0.486             13.9              19.1             0.729   \n",
       "4                0.488             15.4              20.5             0.754   \n",
       "...                ...              ...               ...               ...   \n",
       "9545             0.543             17.0              21.7             0.783   \n",
       "9546             0.531             18.1              22.3             0.812   \n",
       "9547             0.540             18.0              23.1             0.778   \n",
       "9548             0.519             17.0              23.1             0.734   \n",
       "9549             0.546             16.8              23.0             0.732   \n",
       "\n",
       "      Offense_ORB_Home  Offense_DRB_Home  Offense_TRB_Home  Offense_AST_Home  \\\n",
       "0                 11.7              34.0              45.7              21.7   \n",
       "1                  8.7              31.8              40.6              25.7   \n",
       "2                 10.4              34.3              44.7              27.4   \n",
       "3                 10.0              31.8              41.8              20.6   \n",
       "4                 11.1              32.7              43.8              24.5   \n",
       "...                ...               ...               ...               ...   \n",
       "9545               9.0              34.1              43.1              25.0   \n",
       "9546              10.0              33.9              44.0              24.6   \n",
       "9547              11.2              32.9              44.2              25.7   \n",
       "9548              14.1              35.0              49.2              26.0   \n",
       "9549               9.5              34.5              44.0              24.0   \n",
       "\n",
       "      Offense_STL_Home  Offense_BLK_Home  Offense_PF_Home  Offense_PTS_Home  \\\n",
       "0                  6.3               5.8             18.2             100.8   \n",
       "1                  9.1               4.6             17.8             102.5   \n",
       "2                  9.3               6.0             19.9             110.0   \n",
       "3                  7.9               3.8             20.9              95.7   \n",
       "4                  8.2               3.6             21.2             101.4   \n",
       "...                ...               ...              ...               ...   \n",
       "9545               6.4               5.0             18.8             108.6   \n",
       "9546               7.2               4.2             18.7             113.9   \n",
       "9547               8.8               5.6             21.8             115.9   \n",
       "9548               9.8               6.5             19.8             115.6   \n",
       "9549               7.6               5.2             20.2             112.1   \n",
       "\n",
       "      Defense_Team_Home  Defense_MP_Home  Home_defense_FG  Defense_FGA_Home  \\\n",
       "0                     8            242.4             37.7              86.7   \n",
       "1                     9            240.6             36.5              83.1   \n",
       "2                    24            240.6             37.0              86.4   \n",
       "3                     4            240.9             38.0              82.0   \n",
       "4                     0            242.4             38.1              84.7   \n",
       "...                 ...              ...              ...               ...   \n",
       "9545                 13            241.8             41.3              88.9   \n",
       "9546                  9            240.3             41.9              89.0   \n",
       "9547                 17            241.2             40.2              87.4   \n",
       "9548                 27            241.2             40.3              88.6   \n",
       "9549                 22            243.7             42.6              90.5   \n",
       "\n",
       "      Home_defense_FG%  Defense_3P_Home  Defense_3PA_Home  Defense_3P%_Home  \\\n",
       "0                0.435              6.6              19.6             0.335   \n",
       "1                0.439              8.8              25.8             0.341   \n",
       "2                0.428              7.2              21.4             0.337   \n",
       "3                0.463              8.3              22.6             0.368   \n",
       "4                0.450              7.4              22.0             0.336   \n",
       "...                ...              ...               ...               ...   \n",
       "9545             0.464             11.5              31.8             0.361   \n",
       "9546             0.471             12.8              35.2             0.364   \n",
       "9547             0.460             13.1              37.3             0.350   \n",
       "9548             0.455             12.0              34.5             0.349   \n",
       "9549             0.470             12.6              35.8             0.352   \n",
       "\n",
       "      Defense_2P_Home  Defense_2PA_Home  Home_defense_2P%  Defense_FT_Home  \\\n",
       "0                31.2              67.1             0.465             15.7   \n",
       "1                27.7              57.4             0.483             15.4   \n",
       "2                29.7              65.0             0.458             18.7   \n",
       "3                29.6              59.4             0.499             17.2   \n",
       "4                30.7              62.7             0.490             17.6   \n",
       "...               ...               ...               ...              ...   \n",
       "9545             29.8              57.1             0.522             18.0   \n",
       "9546             29.1              53.7             0.541             15.8   \n",
       "9547             27.2              50.0             0.543             19.8   \n",
       "9548             28.3              54.2             0.522             17.3   \n",
       "9549             30.0              54.7             0.548             17.4   \n",
       "\n",
       "      Defense_FTA_Home  Defense_FT%_Home  Defense_ORB_Home  Defense_DRB_Home  \\\n",
       "0                 21.0             0.749              11.7              31.7   \n",
       "1                 20.1             0.764              11.6              32.1   \n",
       "2                 24.5             0.763              11.7              32.8   \n",
       "3                 22.9             0.751              10.1              33.4   \n",
       "4                 23.3             0.755              10.9              33.8   \n",
       "...                ...               ...               ...               ...   \n",
       "9545              22.3             0.807              10.2              34.0   \n",
       "9546              19.9             0.792              10.2              33.6   \n",
       "9547              25.4             0.780              11.0              34.9   \n",
       "9548              22.4             0.771              10.0              33.0   \n",
       "9549              23.3             0.747              11.0              35.6   \n",
       "\n",
       "      Home_defense_TRB  Home_defense_AST  Defense_STL_Home  Home_defense_BLK  \\\n",
       "0                 43.4              20.2               7.5               5.4   \n",
       "1                 43.6              23.5               7.4               4.9   \n",
       "2                 44.5              21.0               8.3               3.6   \n",
       "3                 43.5              23.4               7.7               5.4   \n",
       "4                 44.7              21.9               7.1               5.3   \n",
       "...                ...               ...               ...               ...   \n",
       "9545              44.2              23.7               7.3               4.2   \n",
       "9546              43.9              25.4               7.0               4.5   \n",
       "9547              45.9              26.2               7.2               4.8   \n",
       "9548              43.0              25.0               7.2               6.0   \n",
       "9549              46.6              26.3               8.3               4.1   \n",
       "\n",
       "      Defense_PF_Home  Home_defense_PTS  \n",
       "0                21.2              97.8  \n",
       "1                19.6              97.1  \n",
       "2                18.8              99.9  \n",
       "3                17.9             101.4  \n",
       "4                18.8             101.2  \n",
       "...               ...               ...  \n",
       "9545             19.9             112.0  \n",
       "9546             20.3             112.4  \n",
       "9547             20.9             113.3  \n",
       "9548             19.8             109.9  \n",
       "9549             20.1             115.1  \n",
       "\n",
       "[9550 rows x 92 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "374ec3ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Visitor_offense_FG%', 'Visitor_offense_2P%', 'Visitor_offense_PTS',\n",
       "       'Visitor_offense_FG', 'Visitor_offense_3P%', 'Visitor_defense_FG%',\n",
       "       'Visitor_offense_Team', 'Home_defense_FG%', 'Home_defense_TRB',\n",
       "       'Home_defense_2P%', 'Home_defense_AST', 'Home_defense_BLK',\n",
       "       'Home_offense_Team', 'Home_offense_FG%', 'Home_offense_3P%',\n",
       "       'Home_defense_FG', 'Home_defense_PTS', 'away_team_odds',\n",
       "       'home_team_odds'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df3[[\n",
    "    'Visitor_offense_FG%',\n",
    "    'Visitor_offense_2P%',\n",
    "    'Visitor_offense_PTS',\n",
    "    'Visitor_offense_FG',\n",
    "    'Visitor_offense_3P%',\n",
    "    'Visitor_defense_FG%',\n",
    "    'Visitor_offense_Team',\n",
    "    'Home_defense_FG%',\n",
    "    'Home_defense_TRB',\n",
    "    'Home_defense_2P%',\n",
    "    'Home_defense_AST',\n",
    "    'Home_defense_BLK',\n",
    "    'Home_offense_Team',\n",
    "    'Home_offense_FG%',\n",
    "    'Home_offense_3P%',\n",
    "    'Home_defense_FG',\n",
    "    'Home_defense_PTS',\n",
    "    'away_team_odds',\n",
    "    'home_team_odds'\n",
    "]]\n",
    "\n",
    "y = df3['Home_Winner']\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96f1e4d1-10c1-481a-9759-f1b6a8283704",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling data\n",
    "# Columns that should not be scaled\n",
    "# columns_to_exclude = ['Visitor_offense_Team', 'away_team_odds', 'Home_offense_Team', 'home_team_odds']\n",
    "\n",
    "# # Separate the data into the columns to scale and columns to exclude\n",
    "# columns_to_scale = X.drop(columns=columns_to_exclude).columns  # All other columns\n",
    "\n",
    "# # Create a scaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# # Scale the columns that need scaling\n",
    "# df_scaled = pd.DataFrame(scaler.fit_transform(X[columns_to_scale]), columns=columns_to_scale)\n",
    "# # joblib.dump(scaler, 'scaler_nba.joblib')\n",
    "# # Concatenate the scaled columns back with the excluded columns\n",
    "# df_final = pd.concat([X[columns_to_exclude].reset_index(drop=True), df_scaled.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# # Display the resulting DataFrame\n",
    "# df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ffa51c1-972a-4f08-967e-708dfa9a020a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = df_final[[\n",
    "# 'Home_Decimal',  \n",
    "# 'Decimal_Visitor',    \n",
    "# 'Offense_FG%_Visitor', \n",
    "# 'Defense_FG%_Home',    \n",
    "# 'Defense_TRB_Home',     \n",
    "# 'Offense_2P%_Visitor',  \n",
    "# 'Defense_DRB_Home',      \n",
    "# 'Offense_FG%_Home',     \n",
    "# 'Defense_2P%_Home',       \n",
    "# 'Offense_PTS_Visitor',   \n",
    "# 'Defense_AST_Home',       \n",
    "# 'Offense_FG_Visitor',     \n",
    "# 'Offense_3P%_Visitor',    \n",
    "# 'Defense_FG%_Visitor',    \n",
    "# 'Defense_BLK_Home',      \n",
    "# 'Defense_FG_Home',\n",
    "#         'Home',\n",
    "#         'Visitor',\n",
    "# 'Offense_3P%_Home',        \n",
    "# 'Defense_PTS_Home']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe869ba3-7d13-4813-b62d-5ec23b53f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Further split training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "510c4f7a-9460-4d83-9745-27103e3aa4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch > 10:  # After the first 10 epochs\n",
    "        lr = lr * tf.math.exp(-0.1)  # Reduce the learning rate\n",
    "    return float(lr)  # Ensure the output is a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f8ac6fc-53f3-46dd-9d54-e41e1948acb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-11-06 15:18:18,897] A new study created in memory with name: no-name-3efa7812-6a7c-47d3-8499-58bbe518604b\n",
      "[I 2024-11-06 15:19:07,161] Trial 0 finished with value: 0.6638743281364441 and parameters: {'num_layers': 5, 'units_0': 934, 'activation': 'relu', 'dropout_0': 0.3843528901244361, 'l2': 0.00033955494693743596, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 451, 'dropout_1': 0.14058955713510835, 'units_2': 428, 'dropout_2': 0.42162295257049287, 'units_3': 488, 'dropout_3': 0.20093962985743033, 'units_4': 204, 'dropout_4': 0.18861907764894786, 'optimizer': 'adam', 'learning_rate': 0.09584776948168051, 'beta_1': 0.9807678062276763, 'beta_2': 0.9965356747947451, 'epsilon': 8.40761736205325e-08, 'epochs': 75, 'batch_size': 64}. Best is trial 0 with value: 0.6638743281364441.\n",
      "[I 2024-11-06 15:19:15,846] Trial 1 finished with value: 0.563874363899231 and parameters: {'num_layers': 5, 'units_0': 418, 'activation': 'tanh', 'dropout_0': 0.4366521798177132, 'l2': 1.4325299420344762e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 952, 'dropout_1': 0.46544735304010665, 'units_2': 476, 'dropout_2': 0.4139600265227603, 'units_3': 334, 'dropout_3': 0.42761803916374197, 'units_4': 52, 'dropout_4': 0.42132011608906994, 'optimizer': 'sgd', 'learning_rate': 0.009498314865645946, 'momentum': 0.0599473613368253, 'epochs': 19, 'batch_size': 128}. Best is trial 0 with value: 0.6638743281364441.\n",
      "[I 2024-11-06 15:19:19,822] Trial 2 finished with value: 0.43612566590309143 and parameters: {'num_layers': 2, 'units_0': 720, 'activation': 'tanh', 'dropout_0': 0.36204144861602683, 'l2': 1.5220295619830484e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 893, 'dropout_1': 0.29393120053424504, 'optimizer': 'rmsprop', 'learning_rate': 0.03191570141655401, 'epochs': 62, 'batch_size': 64}. Best is trial 0 with value: 0.6638743281364441.\n",
      "[I 2024-11-06 15:19:23,611] Trial 3 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 998, 'activation': 'sigmoid', 'dropout_0': 0.20699663515569863, 'l2': 3.680793074470448e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 404, 'dropout_1': 0.3258552447630657, 'optimizer': 'adam', 'learning_rate': 0.020756212059300654, 'beta_1': 0.7891787868568741, 'beta_2': 0.9513831872817421, 'epsilon': 5.800464618169017e-07, 'epochs': 46, 'batch_size': 128}. Best is trial 0 with value: 0.6638743281364441.\n",
      "[I 2024-11-06 15:19:27,284] Trial 4 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 1051, 'activation': 'tanh', 'dropout_0': 0.2666502593984942, 'l2': 1.718068229472394e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 60, 'dropout_1': 0.23147724603533823, 'optimizer': 'rmsprop', 'learning_rate': 0.03130861418184978, 'epochs': 30, 'batch_size': 128}. Best is trial 0 with value: 0.6638743281364441.\n",
      "[I 2024-11-06 15:19:45,307] Trial 5 finished with value: 0.6696335077285767 and parameters: {'num_layers': 4, 'units_0': 240, 'activation': 'tanh', 'dropout_0': 0.152528370276388, 'l2': 0.00014285677634394206, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 510, 'dropout_1': 0.4022315215640695, 'units_2': 90, 'dropout_2': 0.47607891841390615, 'units_3': 963, 'dropout_3': 0.2216909577197151, 'optimizer': 'sgd', 'learning_rate': 0.012095809466416554, 'momentum': 0.35445534256410366, 'epochs': 54, 'batch_size': 32}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:20:18,423] Trial 6 finished with value: 0.43612566590309143 and parameters: {'num_layers': 3, 'units_0': 504, 'activation': 'tanh', 'dropout_0': 0.2999055386060994, 'l2': 0.00020257070020687282, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 667, 'dropout_1': 0.3824414074831176, 'units_2': 670, 'dropout_2': 0.2226679723413569, 'optimizer': 'rmsprop', 'learning_rate': 0.08751507971643893, 'epochs': 27, 'batch_size': 16}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:20:25,521] Trial 7 finished with value: 0.5926701426506042 and parameters: {'num_layers': 3, 'units_0': 33, 'activation': 'relu', 'dropout_0': 0.3363162269667327, 'l2': 4.107215133757864e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 18, 'dropout_1': 0.21155309449260182, 'units_2': 666, 'dropout_2': 0.4929880684504969, 'optimizer': 'sgd', 'learning_rate': 0.09750745856238452, 'momentum': 0.7786331383621574, 'epochs': 91, 'batch_size': 32}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:21:19,654] Trial 8 finished with value: 0.563874363899231 and parameters: {'num_layers': 7, 'units_0': 156, 'activation': 'sigmoid', 'dropout_0': 0.1254715610236188, 'l2': 2.8825287341974487e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 664, 'dropout_1': 0.49633274081083223, 'units_2': 23, 'dropout_2': 0.1302133564227531, 'units_3': 1032, 'dropout_3': 0.144400523388682, 'units_4': 1034, 'dropout_4': 0.1151987576259936, 'units_5': 446, 'dropout_5': 0.27427836130895505, 'units_6': 713, 'dropout_6': 0.18739754499378358, 'optimizer': 'sgd', 'learning_rate': 0.062329131010229355, 'momentum': 0.3739865617399817, 'epochs': 51, 'batch_size': 32}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:22:38,497] Trial 9 finished with value: 0.6235601902008057 and parameters: {'num_layers': 7, 'units_0': 282, 'activation': 'tanh', 'dropout_0': 0.11134586292715942, 'l2': 1.9101195380974527e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 267, 'dropout_1': 0.4174243401343899, 'units_2': 21, 'dropout_2': 0.3048295377795931, 'units_3': 1049, 'dropout_3': 0.2864487557110559, 'units_4': 814, 'dropout_4': 0.48425407550318955, 'units_5': 916, 'dropout_5': 0.4864975471191993, 'units_6': 71, 'dropout_6': 0.42817324489592046, 'optimizer': 'sgd', 'learning_rate': 0.0031460643156603213, 'momentum': 0.3824684191097316, 'epochs': 100, 'batch_size': 32}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:22:48,395] Trial 10 finished with value: 0.43612566590309143 and parameters: {'num_layers': 4, 'units_0': 668, 'activation': 'relu', 'dropout_0': 0.1943883061343235, 'l2': 0.000865567770589029, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 794, 'dropout_1': 0.36486083641994155, 'units_2': 249, 'dropout_2': 0.3173584127726996, 'units_3': 27, 'dropout_3': 0.3624182353891897, 'optimizer': 'sgd', 'learning_rate': 0.054769369641944815, 'momentum': 0.048854368665875836, 'epochs': 73, 'batch_size': 16}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:23:01,036] Trial 11 finished with value: 0.5989528894424438 and parameters: {'num_layers': 5, 'units_0': 774, 'activation': 'relu', 'dropout_0': 0.4862828874250112, 'l2': 9.309935754686647e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 456, 'dropout_1': 0.13568689723976377, 'units_2': 963, 'dropout_2': 0.4986272550729571, 'units_3': 618, 'dropout_3': 0.18596637355041373, 'units_4': 185, 'dropout_4': 0.18273231353512268, 'optimizer': 'adam', 'learning_rate': 0.07240648409189833, 'beta_1': 0.9723421483806548, 'beta_2': 0.9964422274143948, 'epsilon': 2.0236580001579316e-08, 'epochs': 75, 'batch_size': 64}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:23:22,346] Trial 12 finished with value: 0.5712041854858398 and parameters: {'num_layers': 6, 'units_0': 326, 'activation': 'relu', 'dropout_0': 0.40947828502047495, 'l2': 0.0008893935831480428, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 280, 'dropout_1': 0.1021526527341672, 'units_2': 344, 'dropout_2': 0.4056488703576254, 'units_3': 644, 'dropout_3': 0.24121871426896907, 'units_4': 479, 'dropout_4': 0.2726897458982153, 'units_5': 18, 'dropout_5': 0.1349001731036436, 'optimizer': 'adam', 'learning_rate': 0.042943394702122786, 'beta_1': 0.509041266402956, 'beta_2': 0.9983283300194522, 'epsilon': 3.2032664330880515e-08, 'epochs': 72, 'batch_size': 64}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:23:46,478] Trial 13 finished with value: 0.6178010702133179 and parameters: {'num_layers': 4, 'units_0': 869, 'activation': 'relu', 'dropout_0': 0.21329639247134036, 'l2': 0.000151805418197706, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 586, 'dropout_1': 0.19169903035833133, 'units_2': 245, 'dropout_2': 0.4091052178718386, 'units_3': 439, 'dropout_3': 0.11897187360053929, 'optimizer': 'adam', 'learning_rate': 0.07533103353567744, 'beta_1': 0.985436385007092, 'beta_2': 0.9039044755042529, 'epsilon': 9.663066049703637e-07, 'epochs': 44, 'batch_size': 64}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:24:40,601] Trial 14 finished with value: 0.563874363899231 and parameters: {'num_layers': 6, 'units_0': 550, 'activation': 'sigmoid', 'dropout_0': 0.2592115458584184, 'l2': 5.628943363608804e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 372, 'dropout_1': 0.2849799065531585, 'units_2': 957, 'dropout_2': 0.3743738739558734, 'units_3': 805, 'dropout_3': 0.23284959093330165, 'units_4': 375, 'dropout_4': 0.276728273473663, 'units_5': 1013, 'dropout_5': 0.457816919929839, 'optimizer': 'adam', 'learning_rate': 0.046053980545547976, 'beta_1': 0.7910875956124304, 'beta_2': 0.9573746197632675, 'epsilon': 3.5596342904114237e-07, 'epochs': 61, 'batch_size': 32}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:24:45,885] Trial 15 finished with value: 0.563874363899231 and parameters: {'num_layers': 5, 'units_0': 147, 'activation': 'tanh', 'dropout_0': 0.3694470767364442, 'l2': 6.100582822867169e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 205, 'dropout_1': 0.42215078412588214, 'units_2': 494, 'dropout_2': 0.4613102517677384, 'units_3': 228, 'dropout_3': 0.3133739949878574, 'units_4': 308, 'dropout_4': 0.19177680580787052, 'optimizer': 'sgd', 'learning_rate': 0.0992930717758669, 'momentum': 0.6677805574740174, 'epochs': 84, 'batch_size': 64}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:25:08,200] Trial 16 finished with value: 0.563874363899231 and parameters: {'num_layers': 4, 'units_0': 862, 'activation': 'relu', 'dropout_0': 0.16549623968893798, 'l2': 0.0003679924251907735, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 529, 'dropout_1': 0.2502859220423841, 'units_2': 193, 'dropout_2': 0.3508052468795304, 'units_3': 803, 'dropout_3': 0.1980647548895439, 'optimizer': 'adam', 'learning_rate': 0.02500225080607546, 'beta_1': 0.6334039275198445, 'beta_2': 0.9697563762150879, 'epsilon': 3.597913156285067e-07, 'epochs': 39, 'batch_size': 32}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:28:17,545] Trial 17 finished with value: 0.6685863733291626 and parameters: {'num_layers': 6, 'units_0': 627, 'activation': 'relu', 'dropout_0': 0.428181940403982, 'l2': 6.359063983730958e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 716, 'dropout_1': 0.17767952727344594, 'units_2': 758, 'dropout_2': 0.2441738193498394, 'units_3': 839, 'dropout_3': 0.2891686978727442, 'units_4': 731, 'dropout_4': 0.35262674691628987, 'units_5': 19, 'dropout_5': 0.10112655224111367, 'optimizer': 'adam', 'learning_rate': 0.012122230342991244, 'beta_1': 0.8921167675971612, 'beta_2': 0.9199809346970561, 'epsilon': 7.044484124778519e-07, 'epochs': 57, 'batch_size': 16}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:28:56,614] Trial 18 finished with value: 0.563874363899231 and parameters: {'num_layers': 6, 'units_0': 577, 'activation': 'tanh', 'dropout_0': 0.49131461471213594, 'l2': 5.850616550175407e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 810, 'dropout_1': 0.3334557770100899, 'units_2': 765, 'dropout_2': 0.23328566069721732, 'units_3': 879, 'dropout_3': 0.3734195055533587, 'units_4': 699, 'dropout_4': 0.3761381688353724, 'units_5': 44, 'dropout_5': 0.10265331997763932, 'optimizer': 'sgd', 'learning_rate': 0.011612216281570359, 'momentum': 0.5470504241900852, 'epochs': 58, 'batch_size': 16}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:29:20,589] Trial 19 finished with value: 0.6539267301559448 and parameters: {'num_layers': 3, 'units_0': 396, 'activation': 'sigmoid', 'dropout_0': 0.4515244597247102, 'l2': 2.38619367609968e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 740, 'dropout_1': 0.1733408848521698, 'units_2': 819, 'dropout_2': 0.23235090832234553, 'optimizer': 'rmsprop', 'learning_rate': 0.0010458427515596357, 'epochs': 34, 'batch_size': 16}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:30:17,145] Trial 20 finished with value: 0.563874363899231 and parameters: {'num_layers': 6, 'units_0': 253, 'activation': 'tanh', 'dropout_0': 0.3237411417758774, 'l2': 2.6112917966029284e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 1037, 'dropout_1': 0.25286239857302173, 'units_2': 622, 'dropout_2': 0.1587928622197927, 'units_3': 928, 'dropout_3': 0.4882495638544912, 'units_4': 699, 'dropout_4': 0.368932864977761, 'units_5': 376, 'dropout_5': 0.2691674568116136, 'optimizer': 'adam', 'learning_rate': 0.018704435662625137, 'beta_1': 0.8294493977334756, 'beta_2': 0.9102432565288643, 'epsilon': 8.368275671818465e-07, 'epochs': 15, 'batch_size': 16}. Best is trial 5 with value: 0.6696335077285767.\n",
      "[I 2024-11-06 15:33:36,742] Trial 21 finished with value: 0.672251284122467 and parameters: {'num_layers': 5, 'units_0': 940, 'activation': 'relu', 'dropout_0': 0.398148742408157, 'l2': 5.982346166983783e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 537, 'dropout_1': 0.14883913310684085, 'units_2': 830, 'dropout_2': 0.2681595941903565, 'units_3': 679, 'dropout_3': 0.2781205121486017, 'units_4': 590, 'dropout_4': 0.2133255190666699, 'optimizer': 'adam', 'learning_rate': 0.03929445250892297, 'beta_1': 0.9054672436040574, 'beta_2': 0.929804144333196, 'epsilon': 7.261844183259026e-07, 'epochs': 67, 'batch_size': 16}. Best is trial 21 with value: 0.672251284122467.\n",
      "[I 2024-11-06 15:35:43,425] Trial 22 finished with value: 0.6319371461868286 and parameters: {'num_layers': 4, 'units_0': 665, 'activation': 'relu', 'dropout_0': 0.4228426333041502, 'l2': 5.132958499202041e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 556, 'dropout_1': 0.15845739854015467, 'units_2': 871, 'dropout_2': 0.2698670603178684, 'units_3': 721, 'dropout_3': 0.2984525809674257, 'optimizer': 'adam', 'learning_rate': 0.03445468733968748, 'beta_1': 0.890712069494045, 'beta_2': 0.924558207017864, 'epsilon': 6.842592271856196e-07, 'epochs': 54, 'batch_size': 16}. Best is trial 21 with value: 0.672251284122467.\n",
      "[I 2024-11-06 15:37:33,666] Trial 23 finished with value: 0.6602094173431396 and parameters: {'num_layers': 5, 'units_0': 802, 'activation': 'relu', 'dropout_0': 0.4568610509304578, 'l2': 1.4373696261238181e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 650, 'dropout_1': 0.10701692974722923, 'units_2': 739, 'dropout_2': 0.20324712472682632, 'units_3': 731, 'dropout_3': 0.26103946735925404, 'units_4': 645, 'dropout_4': 0.31742494461148985, 'optimizer': 'adam', 'learning_rate': 0.01308888681924006, 'beta_1': 0.6831824689840943, 'beta_2': 0.9287640406711908, 'epsilon': 7.43110216556224e-07, 'epochs': 66, 'batch_size': 16}. Best is trial 21 with value: 0.672251284122467.\n",
      "[I 2024-11-06 15:41:57,952] Trial 24 finished with value: 0.6643978953361511 and parameters: {'num_layers': 7, 'units_0': 473, 'activation': 'relu', 'dropout_0': 0.27583979594831387, 'l2': 7.196961865765778e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 503, 'dropout_1': 0.21215044262501376, 'units_2': 1042, 'dropout_2': 0.27074895630082846, 'units_3': 926, 'dropout_3': 0.33959740066232996, 'units_4': 930, 'dropout_4': 0.23486889851432324, 'units_5': 692, 'dropout_5': 0.17394018501959463, 'units_6': 1048, 'dropout_6': 0.4865153795632422, 'optimizer': 'adam', 'learning_rate': 0.04010886507090368, 'beta_1': 0.8878718479294092, 'beta_2': 0.930589527971213, 'epsilon': 4.873104615633611e-07, 'epochs': 50, 'batch_size': 16}. Best is trial 21 with value: 0.672251284122467.\n",
      "[I 2024-11-06 15:42:48,951] Trial 25 finished with value: 0.6659685969352722 and parameters: {'num_layers': 6, 'units_0': 616, 'activation': 'relu', 'dropout_0': 0.4018415351982996, 'l2': 2.1269595038438556e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 605, 'dropout_1': 0.26571627393854913, 'units_2': 576, 'dropout_2': 0.18407083894761533, 'units_3': 625, 'dropout_3': 0.26589019681246207, 'units_4': 551, 'dropout_4': 0.3358848402007892, 'units_5': 306, 'dropout_5': 0.38533348332943973, 'optimizer': 'sgd', 'learning_rate': 0.02263137176577326, 'momentum': 0.2607435104773692, 'epochs': 66, 'batch_size': 32}. Best is trial 21 with value: 0.672251284122467.\n",
      "[I 2024-11-06 15:43:19,223] Trial 26 finished with value: 0.563874363899231 and parameters: {'num_layers': 4, 'units_0': 167, 'activation': 'relu', 'dropout_0': 0.32899885221606856, 'l2': 5.9433597073820105e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 718, 'dropout_1': 0.18194951180519606, 'units_2': 883, 'dropout_2': 0.3382800583473578, 'units_3': 841, 'dropout_3': 0.16354857196398698, 'optimizer': 'adam', 'learning_rate': 0.052768721728476686, 'beta_1': 0.8893743162353495, 'beta_2': 0.9385934618350052, 'epsilon': 9.875229138700363e-07, 'epochs': 81, 'batch_size': 16}. Best is trial 21 with value: 0.672251284122467.\n",
      "[I 2024-11-06 15:44:05,229] Trial 27 finished with value: 0.4434554874897003 and parameters: {'num_layers': 5, 'units_0': 926, 'activation': 'relu', 'dropout_0': 0.2433617531595224, 'l2': 0.0001676189555456138, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 348, 'dropout_1': 0.3275917886800809, 'units_2': 727, 'dropout_2': 0.2700702722632251, 'units_3': 967, 'dropout_3': 0.23459425712153287, 'units_4': 840, 'dropout_4': 0.1176845239957724, 'optimizer': 'adam', 'learning_rate': 0.006399722849621728, 'beta_1': 0.6819915359532235, 'beta_2': 0.9166964555240599, 'epsilon': 8.069520034446162e-07, 'epochs': 43, 'batch_size': 16}. Best is trial 21 with value: 0.672251284122467.\n",
      "[I 2024-11-06 15:44:45,424] Trial 28 finished with value: 0.6738219857215881 and parameters: {'num_layers': 3, 'units_0': 16, 'activation': 'sigmoid', 'dropout_0': 0.14976038744886977, 'l2': 3.55716169303235e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 886, 'dropout_1': 0.13298288751973386, 'units_2': 826, 'dropout_2': 0.2844021706215475, 'optimizer': 'rmsprop', 'learning_rate': 0.01479432063136402, 'epochs': 67, 'batch_size': 32}. Best is trial 28 with value: 0.6738219857215881.\n",
      "[I 2024-11-06 15:45:19,869] Trial 29 finished with value: 0.563874363899231 and parameters: {'num_layers': 4, 'units_0': 40, 'activation': 'sigmoid', 'dropout_0': 0.14356874457346924, 'l2': 0.0003677311037185836, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1048, 'dropout_1': 0.13826938114152185, 'units_2': 395, 'dropout_2': 0.35997529224682967, 'units_3': 369, 'dropout_3': 0.10955812706528728, 'optimizer': 'rmsprop', 'learning_rate': 0.026921499700296298, 'epochs': 85, 'batch_size': 32}. Best is trial 28 with value: 0.6738219857215881.\n",
      "[I 2024-11-06 15:46:13,167] Trial 30 finished with value: 0.6706806421279907 and parameters: {'num_layers': 3, 'units_0': 204, 'activation': 'sigmoid', 'dropout_0': 0.16631905260915053, 'l2': 3.658916957301082e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 889, 'dropout_1': 0.12409171124849455, 'units_2': 1015, 'dropout_2': 0.29323730763138045, 'optimizer': 'rmsprop', 'learning_rate': 0.01677285192837871, 'epochs': 69, 'batch_size': 32}. Best is trial 28 with value: 0.6738219857215881.\n",
      "[I 2024-11-06 15:47:06,125] Trial 31 finished with value: 0.6753926873207092 and parameters: {'num_layers': 3, 'units_0': 92, 'activation': 'sigmoid', 'dropout_0': 0.17319389098999488, 'l2': 2.969867547746161e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 821, 'dropout_1': 0.1263021209688, 'units_2': 1046, 'dropout_2': 0.29330035171113705, 'optimizer': 'rmsprop', 'learning_rate': 0.01638515339961452, 'epochs': 79, 'batch_size': 32}. Best is trial 31 with value: 0.6753926873207092.\n",
      "[I 2024-11-06 15:47:54,403] Trial 32 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 64, 'activation': 'sigmoid', 'dropout_0': 0.10277440916212006, 'l2': 3.591359118524021e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 915, 'dropout_1': 0.12411562603727552, 'units_2': 1029, 'dropout_2': 0.2844436507842878, 'optimizer': 'rmsprop', 'learning_rate': 0.01846039838383174, 'epochs': 68, 'batch_size': 32}. Best is trial 31 with value: 0.6753926873207092.\n",
      "[I 2024-11-06 15:48:37,993] Trial 33 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 87, 'activation': 'sigmoid', 'dropout_0': 0.1780865274802682, 'l2': 1.787362020653477e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 856, 'dropout_1': 0.14165976345594378, 'units_2': 948, 'dropout_2': 0.31646236790048554, 'optimizer': 'rmsprop', 'learning_rate': 0.038127651172400266, 'epochs': 79, 'batch_size': 32}. Best is trial 31 with value: 0.6753926873207092.\n",
      "[I 2024-11-06 15:48:47,159] Trial 34 finished with value: 0.6748691201210022 and parameters: {'num_layers': 2, 'units_0': 122, 'activation': 'sigmoid', 'dropout_0': 0.22819803955938125, 'l2': 9.56837925695884e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 972, 'dropout_1': 0.15457709078684279, 'optimizer': 'rmsprop', 'learning_rate': 0.03095099322522823, 'epochs': 90, 'batch_size': 128}. Best is trial 31 with value: 0.6753926873207092.\n",
      "[I 2024-11-06 15:48:55,130] Trial 35 finished with value: 0.6706806421279907 and parameters: {'num_layers': 2, 'units_0': 101, 'activation': 'sigmoid', 'dropout_0': 0.242586156609499, 'l2': 1.3612314217851199e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 966, 'dropout_1': 0.15653853211895996, 'optimizer': 'rmsprop', 'learning_rate': 0.028970899503535815, 'epochs': 92, 'batch_size': 128}. Best is trial 31 with value: 0.6753926873207092.\n",
      "[I 2024-11-06 15:49:08,525] Trial 36 finished with value: 0.6732984185218811 and parameters: {'num_layers': 2, 'units_0': 312, 'activation': 'sigmoid', 'dropout_0': 0.22802597728431004, 'l2': 2.969209275147315e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 980, 'dropout_1': 0.20563948568779306, 'optimizer': 'rmsprop', 'learning_rate': 0.034760821370675196, 'epochs': 90, 'batch_size': 128}. Best is trial 31 with value: 0.6753926873207092.\n",
      "[I 2024-11-06 15:49:12,304] Trial 37 finished with value: 0.43612566590309143 and parameters: {'num_layers': 2, 'units_0': 372, 'activation': 'sigmoid', 'dropout_0': 0.22912137539736935, 'l2': 9.766815608879547e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 976, 'dropout_1': 0.20735392011885628, 'optimizer': 'rmsprop', 'learning_rate': 0.03408108416546178, 'epochs': 92, 'batch_size': 128}. Best is trial 31 with value: 0.6753926873207092.\n",
      "[I 2024-11-06 15:49:20,117] Trial 38 finished with value: 0.6759162545204163 and parameters: {'num_layers': 2, 'units_0': 121, 'activation': 'sigmoid', 'dropout_0': 0.19510993171840554, 'l2': 3.5848828497942625e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 993, 'dropout_1': 0.22890650893985082, 'optimizer': 'rmsprop', 'learning_rate': 0.024098900562535486, 'epochs': 98, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:49:24,191] Trial 39 finished with value: 0.6649214625358582 and parameters: {'num_layers': 2, 'units_0': 124, 'activation': 'sigmoid', 'dropout_0': 0.1893116857422677, 'l2': 1.2314958527582027e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 849, 'dropout_1': 0.22626126803576696, 'optimizer': 'rmsprop', 'learning_rate': 0.006562852537067256, 'epochs': 98, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:49:35,990] Trial 40 finished with value: 0.6727748513221741 and parameters: {'num_layers': 2, 'units_0': 209, 'activation': 'sigmoid', 'dropout_0': 0.13003798814168954, 'l2': 1.105593517476381e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 929, 'dropout_1': 0.16650198650258324, 'optimizer': 'rmsprop', 'learning_rate': 0.023169668370171134, 'epochs': 96, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:49:43,454] Trial 41 finished with value: 0.6691099405288696 and parameters: {'num_layers': 2, 'units_0': 29, 'activation': 'sigmoid', 'dropout_0': 0.20256256638608264, 'l2': 3.756117417522964e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 998, 'dropout_1': 0.1937313252486274, 'optimizer': 'rmsprop', 'learning_rate': 0.030981393967133966, 'epochs': 88, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:49:52,659] Trial 42 finished with value: 0.6727748513221741 and parameters: {'num_layers': 2, 'units_0': 335, 'activation': 'sigmoid', 'dropout_0': 0.21868430377806355, 'l2': 3.221056394139048e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1010, 'dropout_1': 0.23654250132278612, 'optimizer': 'rmsprop', 'learning_rate': 0.016371552510515593, 'epochs': 77, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:49:58,383] Trial 43 finished with value: 0.43612566590309143 and parameters: {'num_layers': 3, 'units_0': 191, 'activation': 'sigmoid', 'dropout_0': 0.28618666361560585, 'l2': 6.826505394249077e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 805, 'dropout_1': 0.11862817127393047, 'units_2': 884, 'dropout_2': 0.43658905608886606, 'optimizer': 'rmsprop', 'learning_rate': 0.028904272028005863, 'epochs': 88, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:50:09,626] Trial 44 finished with value: 0.6727748513221741 and parameters: {'num_layers': 2, 'units_0': 272, 'activation': 'sigmoid', 'dropout_0': 0.1461428496244853, 'l2': 8.681550592683617e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 943, 'dropout_1': 0.20181838263686536, 'optimizer': 'rmsprop', 'learning_rate': 0.04718385985987862, 'epochs': 82, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:50:25,039] Trial 45 finished with value: 0.6727748513221741 and parameters: {'num_layers': 3, 'units_0': 105, 'activation': 'sigmoid', 'dropout_0': 0.18392539501882565, 'l2': 3.902316854842076e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 877, 'dropout_1': 0.2837095808343306, 'units_2': 555, 'dropout_2': 0.11981961915741698, 'optimizer': 'rmsprop', 'learning_rate': 0.021580995664381774, 'epochs': 95, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:50:26,550] Trial 46 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 20, 'activation': 'sigmoid', 'dropout_0': 0.2323886321083157, 'l2': 1.7930383069957045e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1053, 'dropout_1': 0.10168933306288776, 'optimizer': 'rmsprop', 'learning_rate': 0.056796341156664154, 'epochs': 89, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:50:38,810] Trial 47 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 145, 'activation': 'sigmoid', 'dropout_0': 0.1270763411848928, 'l2': 6.680926450480481e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 776, 'dropout_1': 0.15868982563833148, 'units_2': 677, 'dropout_2': 0.3775591553952063, 'optimizer': 'rmsprop', 'learning_rate': 0.033439338012504795, 'epochs': 100, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:51:03,131] Trial 48 finished with value: 0.6717277765274048 and parameters: {'num_layers': 2, 'units_0': 226, 'activation': 'sigmoid', 'dropout_0': 0.15900703115211606, 'l2': 9.35956555458773e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 957, 'dropout_1': 0.2230500148014147, 'optimizer': 'rmsprop', 'learning_rate': 0.007004283217822719, 'epochs': 74, 'batch_size': 32}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:51:08,052] Trial 49 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 447, 'activation': 'sigmoid', 'dropout_0': 0.2509946626042829, 'l2': 2.57132854682468e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 839, 'dropout_1': 0.1785902552272024, 'units_2': 920, 'dropout_2': 0.19164407424506186, 'optimizer': 'rmsprop', 'learning_rate': 0.02577946615754147, 'epochs': 85, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:51:28,881] Trial 50 finished with value: 0.6717277765274048 and parameters: {'num_layers': 2, 'units_0': 305, 'activation': 'sigmoid', 'dropout_0': 0.20435747746967314, 'l2': 2.385512881420348e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 908, 'dropout_1': 0.12195266223774058, 'optimizer': 'rmsprop', 'learning_rate': 0.08680278785320397, 'epochs': 94, 'batch_size': 64}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:51:38,047] Trial 51 finished with value: 0.6748691201210022 and parameters: {'num_layers': 2, 'units_0': 177, 'activation': 'sigmoid', 'dropout_0': 0.12441584223464061, 'l2': 1.1506408564198257e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 938, 'dropout_1': 0.17033762608406958, 'optimizer': 'rmsprop', 'learning_rate': 0.02448882280781821, 'epochs': 97, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:51:47,050] Trial 52 finished with value: 0.6748691201210022 and parameters: {'num_layers': 2, 'units_0': 68, 'activation': 'sigmoid', 'dropout_0': 0.11767076186660325, 'l2': 1.0712338158278467e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 996, 'dropout_1': 0.18959589611662908, 'optimizer': 'rmsprop', 'learning_rate': 0.014311081966930258, 'epochs': 97, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:51:48,928] Trial 53 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 70, 'activation': 'sigmoid', 'dropout_0': 0.11404354397386682, 'l2': 1.0782502054593002e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1001, 'dropout_1': 0.14318306889612148, 'optimizer': 'rmsprop', 'learning_rate': 0.013235229385415933, 'epochs': 97, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:52:07,695] Trial 54 finished with value: 0.6748691201210022 and parameters: {'num_layers': 3, 'units_0': 172, 'activation': 'sigmoid', 'dropout_0': 0.131885590201251, 'l2': 1.8076470784330266e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 761, 'dropout_1': 0.16895711269074692, 'units_2': 803, 'dropout_2': 0.16835420393684505, 'optimizer': 'rmsprop', 'learning_rate': 0.01633741999301777, 'epochs': 99, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:52:17,066] Trial 55 finished with value: 0.6727748513221741 and parameters: {'num_layers': 2, 'units_0': 158, 'activation': 'sigmoid', 'dropout_0': 0.13445364992860961, 'l2': 4.8048059412466894e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 829, 'dropout_1': 0.19342833426009648, 'optimizer': 'rmsprop', 'learning_rate': 0.020361277958067615, 'epochs': 93, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:52:27,175] Trial 56 finished with value: 0.6612565517425537 and parameters: {'num_layers': 3, 'units_0': 122, 'activation': 'tanh', 'dropout_0': 0.17328745379131988, 'l2': 2.063788571993141e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 752, 'dropout_1': 0.16931883764245048, 'units_2': 478, 'dropout_2': 0.11608603208860702, 'optimizer': 'rmsprop', 'learning_rate': 0.004501855108617852, 'epochs': 99, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:52:36,157] Trial 57 finished with value: 0.6701570749282837 and parameters: {'num_layers': 2, 'units_0': 174, 'activation': 'sigmoid', 'dropout_0': 0.11536642401604816, 'l2': 8.75512408945288e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1021, 'dropout_1': 0.23470458710227143, 'optimizer': 'rmsprop', 'learning_rate': 0.010618909275934072, 'epochs': 86, 'batch_size': 128}. Best is trial 38 with value: 0.6759162545204163.\n",
      "[I 2024-11-06 15:52:53,910] Trial 58 finished with value: 0.6764397621154785 and parameters: {'num_layers': 3, 'units_0': 245, 'activation': 'sigmoid', 'dropout_0': 0.15542480162415667, 'l2': 1.5056663080210335e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 937, 'dropout_1': 0.1831259744641057, 'units_2': 986, 'dropout_2': 0.14756994005540486, 'optimizer': 'rmsprop', 'learning_rate': 0.0012711550817668844, 'epochs': 100, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:52:57,888] Trial 59 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 58, 'activation': 'sigmoid', 'dropout_0': 0.15920045250610038, 'l2': 1.2753719039828038e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 934, 'dropout_1': 0.1887878968836028, 'optimizer': 'sgd', 'learning_rate': 0.0008023635747998953, 'momentum': 0.861204662243158, 'epochs': 96, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:53:12,447] Trial 60 finished with value: 0.6738219857215881 and parameters: {'num_layers': 2, 'units_0': 238, 'activation': 'sigmoid', 'dropout_0': 0.1011249889280306, 'l2': 7.040847371981244e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1054, 'dropout_1': 0.24538051863579552, 'optimizer': 'rmsprop', 'learning_rate': 0.009419262710249473, 'epochs': 91, 'batch_size': 64}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:53:34,988] Trial 61 finished with value: 0.6732984185218811 and parameters: {'num_layers': 3, 'units_0': 135, 'activation': 'sigmoid', 'dropout_0': 0.13871055251446526, 'l2': 1.6884622809154916e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 873, 'dropout_1': 0.15635335499678737, 'units_2': 1014, 'dropout_2': 0.15111480448881734, 'optimizer': 'rmsprop', 'learning_rate': 0.018864616026765195, 'epochs': 100, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:53:54,478] Trial 62 finished with value: 0.6727748513221741 and parameters: {'num_layers': 3, 'units_0': 100, 'activation': 'sigmoid', 'dropout_0': 0.11768625780485654, 'l2': 5.250370790588021e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 688, 'dropout_1': 0.1695634854606638, 'units_2': 979, 'dropout_2': 0.10071368129572988, 'optimizer': 'rmsprop', 'learning_rate': 0.009631274541756975, 'epochs': 95, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:54:02,410] Trial 63 finished with value: 0.563874363899231 and parameters: {'num_layers': 4, 'units_0': 258, 'activation': 'sigmoid', 'dropout_0': 0.19153758862738474, 'l2': 2.8328849903829135e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 778, 'dropout_1': 0.3094942112246573, 'units_2': 920, 'dropout_2': 0.15473335880317654, 'units_3': 39, 'dropout_3': 0.4907088140946228, 'optimizer': 'rmsprop', 'learning_rate': 0.02479062542488287, 'epochs': 25, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:54:22,859] Trial 64 finished with value: 0.6727748513221741 and parameters: {'num_layers': 3, 'units_0': 181, 'activation': 'tanh', 'dropout_0': 0.17174336096301449, 'l2': 9.033070967481715e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 915, 'dropout_1': 0.26329433679232617, 'units_2': 1048, 'dropout_2': 0.1755239646670538, 'optimizer': 'rmsprop', 'learning_rate': 0.0034636759282045404, 'epochs': 100, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:54:30,492] Trial 65 finished with value: 0.6743455529212952 and parameters: {'num_layers': 2, 'units_0': 81, 'activation': 'sigmoid', 'dropout_0': 0.14999591581719715, 'l2': 8.732331364143e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 956, 'dropout_1': 0.21400919015390965, 'optimizer': 'rmsprop', 'learning_rate': 0.01510197630594261, 'epochs': 82, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:54:38,314] Trial 66 finished with value: 0.563874363899231 and parameters: {'num_layers': 4, 'units_0': 210, 'activation': 'sigmoid', 'dropout_0': 0.12921654900377885, 'l2': 3.905908675100439e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 108, 'dropout_1': 0.35491968169011556, 'units_2': 680, 'dropout_2': 0.21190737951247957, 'units_3': 155, 'dropout_3': 0.43222185050949136, 'optimizer': 'rmsprop', 'learning_rate': 0.021534849450181526, 'epochs': 97, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:54:41,457] Trial 67 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 147, 'activation': 'sigmoid', 'dropout_0': 0.1587454090323677, 'l2': 1.5831624645971085e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 627, 'dropout_1': 0.11358985753177148, 'units_2': 981, 'dropout_2': 0.14379056425088166, 'optimizer': 'sgd', 'learning_rate': 0.029783918340052624, 'momentum': 0.19448372420886217, 'epochs': 93, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:54:50,746] Trial 68 finished with value: 0.6706806421279907 and parameters: {'num_layers': 2, 'units_0': 53, 'activation': 'sigmoid', 'dropout_0': 0.18200157584973922, 'l2': 2.056719589191411e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 994, 'dropout_1': 0.15098575536091965, 'optimizer': 'rmsprop', 'learning_rate': 0.026786960677564718, 'epochs': 87, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:55:14,130] Trial 69 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 289, 'activation': 'sigmoid', 'dropout_0': 0.2122047875233352, 'l2': 4.399838304199847e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 827, 'dropout_1': 0.18381489091257447, 'units_2': 605, 'dropout_2': 0.10053318436877223, 'optimizer': 'rmsprop', 'learning_rate': 0.017411947891824767, 'epochs': 90, 'batch_size': 64}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:55:17,221] Trial 70 finished with value: 0.43612566590309143 and parameters: {'num_layers': 2, 'units_0': 126, 'activation': 'tanh', 'dropout_0': 0.3108007863929085, 'l2': 4.443933595929493e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1024, 'dropout_1': 0.13636599491549975, 'optimizer': 'rmsprop', 'learning_rate': 0.013628481569850295, 'epochs': 78, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:55:23,056] Trial 71 finished with value: 0.6701570749282837 and parameters: {'num_layers': 2, 'units_0': 91, 'activation': 'sigmoid', 'dropout_0': 0.14872673955914517, 'l2': 8.08275231055712e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 953, 'dropout_1': 0.2209653110404735, 'optimizer': 'rmsprop', 'learning_rate': 0.015146146988046498, 'epochs': 84, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:55:29,030] Trial 72 finished with value: 0.6753926873207092 and parameters: {'num_layers': 2, 'units_0': 76, 'activation': 'sigmoid', 'dropout_0': 0.12127917934991739, 'l2': 1.1536874019757586e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 895, 'dropout_1': 0.19774052215635457, 'optimizer': 'rmsprop', 'learning_rate': 0.009196908701334465, 'epochs': 94, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:55:35,140] Trial 73 finished with value: 0.6759162545204163 and parameters: {'num_layers': 2, 'units_0': 183, 'activation': 'sigmoid', 'dropout_0': 0.11753928789891062, 'l2': 1.2151829019248902e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 906, 'dropout_1': 0.19927962872131144, 'optimizer': 'rmsprop', 'learning_rate': 0.008438992653293335, 'epochs': 94, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:55:47,344] Trial 74 finished with value: 0.6753926873207092 and parameters: {'num_layers': 2, 'units_0': 230, 'activation': 'sigmoid', 'dropout_0': 0.102606276406291, 'l2': 1.2661900577526013e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 898, 'dropout_1': 0.19527434916687683, 'optimizer': 'rmsprop', 'learning_rate': 0.008230337087603505, 'epochs': 94, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:56:09,750] Trial 75 finished with value: 0.6743455529212952 and parameters: {'num_layers': 2, 'units_0': 229, 'activation': 'sigmoid', 'dropout_0': 0.1079378179911905, 'l2': 5.91966142818313e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 862, 'dropout_1': 0.19599103714274546, 'optimizer': 'rmsprop', 'learning_rate': 0.007948885245278028, 'epochs': 93, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:56:33,764] Trial 76 finished with value: 0.6753926873207092 and parameters: {'num_layers': 2, 'units_0': 342, 'activation': 'sigmoid', 'dropout_0': 0.10094562035803484, 'l2': 2.6260352896988307e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 907, 'dropout_1': 0.2085248405327169, 'optimizer': 'rmsprop', 'learning_rate': 0.0008474781038536154, 'epochs': 89, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:56:46,620] Trial 77 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 350, 'activation': 'sigmoid', 'dropout_0': 0.10711830052757272, 'l2': 2.7581839066593575e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 905, 'dropout_1': 0.2153965972807584, 'optimizer': 'sgd', 'learning_rate': 0.0001948065707504023, 'momentum': 0.5432517625970954, 'epochs': 90, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:57:07,224] Trial 78 finished with value: 0.6706806421279907 and parameters: {'num_layers': 2, 'units_0': 412, 'activation': 'sigmoid', 'dropout_0': 0.19655809008937322, 'l2': 1.0350909096582335e-07, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 799, 'dropout_1': 0.2410604845294726, 'optimizer': 'rmsprop', 'learning_rate': 0.0046048966918287755, 'epochs': 80, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:57:18,398] Trial 79 finished with value: 0.6664921641349792 and parameters: {'num_layers': 2, 'units_0': 258, 'activation': 'sigmoid', 'dropout_0': 0.10023158437966626, 'l2': 1.3854707000695492e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 890, 'dropout_1': 0.26736730223807315, 'optimizer': 'rmsprop', 'learning_rate': 0.003727907163567996, 'epochs': 84, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:57:25,142] Trial 80 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 513, 'activation': 'sigmoid', 'dropout_0': 0.14224069955006502, 'l2': 2.7673645182765243e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 974, 'dropout_1': 0.20732197010450135, 'optimizer': 'rmsprop', 'learning_rate': 0.010268346472267906, 'epochs': 87, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:57:31,828] Trial 81 finished with value: 0.6235601902008057 and parameters: {'num_layers': 2, 'units_0': 207, 'activation': 'sigmoid', 'dropout_0': 0.12168387579770723, 'l2': 1.1678726711910657e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 931, 'dropout_1': 0.1762029102422786, 'optimizer': 'rmsprop', 'learning_rate': 0.006623451538697516, 'epochs': 95, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:57:47,522] Trial 82 finished with value: 0.6738219857215881 and parameters: {'num_layers': 2, 'units_0': 188, 'activation': 'sigmoid', 'dropout_0': 0.1234227625344575, 'l2': 2.2690930221670547e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 860, 'dropout_1': 0.20037659231139623, 'optimizer': 'rmsprop', 'learning_rate': 0.002099641692102224, 'epochs': 92, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:58:06,321] Trial 83 finished with value: 0.6696335077285767 and parameters: {'num_layers': 2, 'units_0': 105, 'activation': 'sigmoid', 'dropout_0': 0.13801988233615592, 'l2': 3.092207881720845e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 908, 'dropout_1': 0.16129061716636842, 'optimizer': 'rmsprop', 'learning_rate': 0.011860757701832828, 'epochs': 90, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:58:35,983] Trial 84 finished with value: 0.672251284122467 and parameters: {'num_layers': 2, 'units_0': 292, 'activation': 'sigmoid', 'dropout_0': 0.34884010606938876, 'l2': 4.7126728374255416e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 934, 'dropout_1': 0.14965007936883942, 'optimizer': 'rmsprop', 'learning_rate': 0.03712008235116036, 'epochs': 94, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:58:52,088] Trial 85 finished with value: 0.6602094173431396 and parameters: {'num_layers': 2, 'units_0': 356, 'activation': 'sigmoid', 'dropout_0': 0.16255562542065263, 'l2': 7.001265435019478e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 884, 'dropout_1': 0.4692776995510056, 'optimizer': 'rmsprop', 'learning_rate': 0.008175189619399592, 'epochs': 98, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:00,546] Trial 86 finished with value: 0.6743455529212952 and parameters: {'num_layers': 2, 'units_0': 157, 'activation': 'sigmoid', 'dropout_0': 0.1728724493289809, 'l2': 6.45999553672748e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1025, 'dropout_1': 0.12895276657540758, 'optimizer': 'rmsprop', 'learning_rate': 0.005043536996990211, 'epochs': 71, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:14,714] Trial 87 finished with value: 0.6617801189422607 and parameters: {'num_layers': 2, 'units_0': 234, 'activation': 'sigmoid', 'dropout_0': 0.11131217799946812, 'l2': 1.478393141740781e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 458, 'dropout_1': 0.22740270972294688, 'optimizer': 'rmsprop', 'learning_rate': 0.042722882791193094, 'epochs': 96, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:31,915] Trial 88 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 131, 'activation': 'tanh', 'dropout_0': 0.15479066477844972, 'l2': 0.0006541587360855486, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 825, 'dropout_1': 0.18281263896212496, 'units_2': 112, 'dropout_2': 0.4437064731710503, 'optimizer': 'rmsprop', 'learning_rate': 0.06590704184614005, 'epochs': 88, 'batch_size': 64}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:34,293] Trial 89 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 385, 'activation': 'sigmoid', 'dropout_0': 0.12479484447535605, 'l2': 9.486959125468373e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 958, 'dropout_1': 0.1426195980866983, 'optimizer': 'rmsprop', 'learning_rate': 0.019558798846609726, 'epochs': 11, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:42,603] Trial 90 finished with value: 0.6743455529212952 and parameters: {'num_layers': 2, 'units_0': 317, 'activation': 'sigmoid', 'dropout_0': 0.13638316437059048, 'l2': 2.34740323752801e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 729, 'dropout_1': 0.25607698281063246, 'optimizer': 'adam', 'learning_rate': 0.0021134928790184143, 'beta_1': 0.5517914607408624, 'beta_2': 0.9786835624519901, 'epsilon': 2.0176294776781485e-07, 'epochs': 76, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:44,191] Trial 91 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 42, 'activation': 'sigmoid', 'dropout_0': 0.11914896288437934, 'l2': 1.739932009948474e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 918, 'dropout_1': 0.18912169892835823, 'optimizer': 'rmsprop', 'learning_rate': 0.02374315625223594, 'epochs': 97, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:46,094] Trial 92 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 64, 'activation': 'sigmoid', 'dropout_0': 0.11015432809441147, 'l2': 1.1390682454089789e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 985, 'dropout_1': 0.2004011437833397, 'optimizer': 'rmsprop', 'learning_rate': 0.011906504123462038, 'epochs': 98, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 15:59:53,566] Trial 93 finished with value: 0.6717277765274048 and parameters: {'num_layers': 2, 'units_0': 106, 'activation': 'sigmoid', 'dropout_0': 0.10047417706795753, 'l2': 1.0228855772575603e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1005, 'dropout_1': 0.1763649763844225, 'optimizer': 'rmsprop', 'learning_rate': 0.005733614142431863, 'epochs': 92, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 16:00:02,699] Trial 94 finished with value: 0.6748691201210022 and parameters: {'num_layers': 2, 'units_0': 193, 'activation': 'sigmoid', 'dropout_0': 0.14476769956798835, 'l2': 6.508393297569197e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 976, 'dropout_1': 0.2164593451466124, 'optimizer': 'rmsprop', 'learning_rate': 0.00896340384449167, 'epochs': 94, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 16:00:05,582] Trial 95 finished with value: 0.563874363899231 and parameters: {'num_layers': 2, 'units_0': 16, 'activation': 'relu', 'dropout_0': 0.12036318169364198, 'l2': 3.1240870414275546e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 1031, 'dropout_1': 0.16265183650815607, 'optimizer': 'rmsprop', 'learning_rate': 0.013671880151726306, 'epochs': 100, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 16:00:20,997] Trial 96 finished with value: 0.5654450058937073 and parameters: {'num_layers': 2, 'units_0': 270, 'activation': 'sigmoid', 'dropout_0': 0.18483166042689095, 'l2': 1.370309753574723e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': True, 'units_1': 850, 'dropout_1': 0.18779907851401056, 'optimizer': 'rmsprop', 'learning_rate': 0.017955083973783103, 'epochs': 89, 'batch_size': 16}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 16:00:24,122] Trial 97 finished with value: 0.563874363899231 and parameters: {'num_layers': 3, 'units_0': 77, 'activation': 'sigmoid', 'dropout_0': 0.22020945991159258, 'l2': 3.773856739486692e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 943, 'dropout_1': 0.2307372202508353, 'units_2': 301, 'dropout_2': 0.39414432347498685, 'optimizer': 'sgd', 'learning_rate': 8.725437026439265e-05, 'momentum': 0.7119528604021315, 'epochs': 96, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 16:01:09,185] Trial 98 finished with value: 0.563874363899231 and parameters: {'num_layers': 4, 'units_0': 160, 'activation': 'sigmoid', 'dropout_0': 0.16725926981659395, 'l2': 1.8467511106105177e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 884, 'dropout_1': 0.21023880129009406, 'units_2': 395, 'dropout_2': 0.47248453307892757, 'units_3': 555, 'dropout_3': 0.4182381099471255, 'optimizer': 'rmsprop', 'learning_rate': 0.027670176226836596, 'epochs': 83, 'batch_size': 32}. Best is trial 58 with value: 0.6764397621154785.\n",
      "[I 2024-11-06 16:01:22,809] Trial 99 finished with value: 0.563874363899231 and parameters: {'num_layers': 7, 'units_0': 219, 'activation': 'sigmoid', 'dropout_0': 0.13487115822975507, 'l2': 2.1893612353087256e-06, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 989, 'dropout_1': 0.1983991259084663, 'units_2': 146, 'dropout_2': 0.24420629694453977, 'units_3': 158, 'dropout_3': 0.45615787799083696, 'units_4': 79, 'dropout_4': 0.4712102182228578, 'units_5': 734, 'dropout_5': 0.34196096833568634, 'units_6': 25, 'dropout_6': 0.10833836333987448, 'optimizer': 'rmsprop', 'learning_rate': 0.03221552379376658, 'epochs': 86, 'batch_size': 128}. Best is trial 58 with value: 0.6764397621154785.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters found:\n",
      "{'num_layers': 3, 'units_0': 245, 'activation': 'sigmoid', 'dropout_0': 0.15542480162415667, 'l2': 1.5056663080210335e-05, 'kernel_initializer': 'glorot_uniform', 'use_batch_norm': False, 'units_1': 937, 'dropout_1': 0.1831259744641057, 'units_2': 986, 'dropout_2': 0.14756994005540486, 'optimizer': 'rmsprop', 'learning_rate': 0.0012711550817668844, 'epochs': 100, 'batch_size': 128}\n"
     ]
    }
   ],
   "source": [
    "# Define the model-building function\n",
    "# Define the model-building function\n",
    "def build_model(trial):\n",
    "    model = models.Sequential()\n",
    "    \n",
    "    # Tune number of layers\n",
    "    num_layers = trial.suggest_int('num_layers', 2, 7)  # Correctly specify low and high\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        # Specify the number of units with the correct method\n",
    "        units = trial.suggest_int(f'units_{i}', 16, 1056)  # Specify name and bounds\n",
    "        \n",
    "        # Suggest activation functions\n",
    "        activation = trial.suggest_categorical('activation', ['relu', 'tanh', 'sigmoid'])  # Correct method\n",
    "        \n",
    "        # Use suggest_float for dropout rate\n",
    "        dropout_rate = trial.suggest_float(f'dropout_{i}', 0.1, 0.5)  # Correct method for float\n",
    "        \n",
    "        l2_reg = trial.suggest_float('l2', 1e-7, 1e-3, log=True)  # Replace with suggest_float\n",
    "\n",
    "        \n",
    "        model.add(layers.Dense(\n",
    "            units=units,\n",
    "            activation=activation,\n",
    "            kernel_initializer=trial.suggest_categorical('kernel_initializer', ['glorot_uniform']),  # Correct method\n",
    "            kernel_regularizer=regularizers.l2(l2_reg)  # Correctly use regularizers\n",
    "\n",
    "        ))\n",
    "\n",
    "        use_batch_norm = trial.suggest_categorical('use_batch_norm', [True, False])\n",
    "        if use_batch_norm:\n",
    "            model.add(layers.BatchNormalization())\n",
    "\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "    \n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    # Choose optimizer\n",
    "    optimizer_name = trial.suggest_categorical('optimizer', ['adam', 'sgd', 'rmsprop'])  # Correct method\n",
    "    if optimizer_name == 'adam':\n",
    "        optimizer = optimizers.Adam(\n",
    "            learning_rate=trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "            beta_1=trial.suggest_float('beta_1', 0.5, 0.99),\n",
    "            beta_2=trial.suggest_float('beta_2', 0.9, 0.999),\n",
    "            epsilon=trial.suggest_float('epsilon', 1e-8, 1e-6)\n",
    "        )\n",
    "    elif optimizer_name == 'sgd':\n",
    "        optimizer = optimizers.SGD(\n",
    "            learning_rate=trial.suggest_float('learning_rate', 1e-5, 1e-1),\n",
    "            momentum=trial.suggest_float('momentum', 0.0, 0.9)  # Correctly suggest momentum\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optimizers.RMSprop(\n",
    "            learning_rate=trial.suggest_float('learning_rate', 1e-5, 1e-1)\n",
    "        )\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Objective function for Optuna\n",
    "# Objective function for Optuna\n",
    "def objective(trial):\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    validation_scores = []\n",
    "\n",
    "    for train_index, val_index in kf.split(X):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "\n",
    "    \n",
    "    model = build_model(trial)\n",
    "    \n",
    "    # Implement early stopping\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    # Learning Rate Scheduler\n",
    "    lr_scheduler = callbacks.LearningRateScheduler(scheduler)\n",
    "\n",
    "    \n",
    "    # Implement model checkpoint\n",
    "    checkpoint_callback = ModelCheckpoint(\n",
    "        filepath=r'C:\\Users\\Joshua\\desktop\\nba_third_try\\model\\not_scaled_nba.keras',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True\n",
    "    )\n",
    "    \n",
    "    # Train the model\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=trial.suggest_int('epochs', 10, 100),  # Use suggest_int for epochs\n",
    "        batch_size=trial.suggest_categorical('batch_size', [16, 32, 64, 128]),  # Use suggest_categorical for batch size\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=[early_stopping, checkpoint_callback, lr_scheduler],\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    val_accuracy = history.history['val_accuracy'][-1]\n",
    "    return val_accuracy\n",
    "\n",
    "\n",
    "# Define Optuna study\n",
    "sampler = TPESampler(n_startup_trials=8)\n",
    "study = optuna.create_study(sampler=sampler, direction='maximize')\n",
    "study.optimize(objective, n_trials=100)  # Adjust n_trials based on computational resources\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters found:\")\n",
    "print(study.best_params)\n",
    "\n",
    "# Load the best model\n",
    "best_model = models.load_model(r'C:\\Users\\Joshua\\desktop\\nba_third_try\\model\\not_scaled_nba.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d430ae3f-00e5-429b-ad8a-ac6e2c913c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V = df[['Visitor', 'Decimal_Visitor', 'Home', 'Home_Decimal', 'Season',\n",
    "#     'Offense_MP_Visitor', 'Offense_FG_Visitor',\n",
    "#        'Offense_FGA_Visitor', 'Offense_FG%_Visitor', 'Offense_3P_Visitor',\n",
    "#        'Offense_3PA_Visitor', 'Offense_3P%_Visitor', 'Offense_2P_Visitor',\n",
    "#        'Offense_2PA_Visitor', 'Offense_2P%_Visitor', 'Offense_FT_Visitor',\n",
    "#        'Offense_FTA_Visitor', 'Offense_FT%_Visitor', 'Offense_ORB_Visitor',\n",
    "#        'Offense_DRB_Visitor', 'Offense_TRB_Visitor', 'Offense_AST_Visitor',\n",
    "#        'Offense_STL_Visitor', 'Offense_BLK_Visitor', 'Offense_PF_Visitor',\n",
    "#        'Offense_PTS_Visitor', 'Defense_Team_Visitor', 'Defense_MP_Visitor',\n",
    "#        'Defense_FG_Visitor', 'Defense_FGA_Visitor', 'Defense_FG%_Visitor',\n",
    "#        'Defense_3P_Visitor', 'Defense_3PA_Visitor', 'Defense_3P%_Visitor',\n",
    "#        'Defense_2P_Visitor', 'Defense_2PA_Visitor', 'Defense_2P%_Visitor',\n",
    "#        'Defense_FT_Visitor', 'Defense_FTA_Visitor', 'Defense_FT%_Visitor',\n",
    "#        'Defense_ORB_Visitor', 'Defense_DRB_Visitor', 'Defense_TRB_Visitor',\n",
    "#        'Defense_AST_Visitor', 'Defense_STL_Visitor', 'Defense_BLK_Visitor',\n",
    "#        'Defense_PF_Visitor', 'Defense_PTS_Visitor', 'Offense_MP_Home',\n",
    "#        'Offense_FG_Home', 'Offense_FGA_Home', 'Offense_FG%_Home',\n",
    "#        'Offense_3P_Home', 'Offense_3PA_Home', 'Offense_3P%_Home',\n",
    "#        'Offense_2P_Home', 'Offense_2PA_Home', 'Offense_2P%_Home',\n",
    "#        'Offense_FT_Home', 'Offense_FTA_Home', 'Offense_FT%_Home',\n",
    "#        'Offense_ORB_Home', 'Offense_DRB_Home', 'Offense_TRB_Home',\n",
    "#        'Offense_AST_Home', 'Offense_STL_Home', 'Offense_BLK_Home',\n",
    "#        'Offense_PF_Home', 'Offense_PTS_Home', 'Defense_Team_Home',\n",
    "#        'Defense_MP_Home', 'Defense_FG_Home', 'Defense_FGA_Home',\n",
    "#        'Defense_FG%_Home', 'Defense_3P_Home', 'Defense_3PA_Home',\n",
    "#        'Defense_3P%_Home', 'Defense_2P_Home', 'Defense_2PA_Home',\n",
    "#        'Defense_2P%_Home', 'Defense_FT_Home', 'Defense_FTA_Home',\n",
    "#        'Defense_FT%_Home', 'Defense_ORB_Home', 'Defense_DRB_Home',\n",
    "#        'Defense_TRB_Home', 'Defense_AST_Home', 'Defense_STL_Home',\n",
    "#        'Defense_BLK_Home', 'Defense_PF_Home', 'Defense_PTS_Home', 'Home_Winner']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d34835d-02cc-497a-974e-3a153bd885da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Set display options to show all rows and avoid truncation\n",
    "# pd.set_option('display.max_rows', None)\n",
    "\n",
    "# # Calculate the correlation matrix (assuming 'df' contains the data)\n",
    "# correlation_matrix = V.corr()\n",
    "\n",
    "# # Print the full list of correlations with the target variable, sorted by absolute value\n",
    "# correlation_with_target = correlation_matrix['Home_Winner'].sort_values(key=abs, ascending=False)\n",
    "# print(correlation_with_target)\n",
    "\n",
    "# # Visualize the correlation matrix with a heatmap\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "# plt.title('Correlation Matrix')\n",
    "# plt.show()\n",
    "\n",
    "# # Reset display options after printing\n",
    "# pd.reset_option('display.max_rows')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43de2077-9617-4fb2-95c0-b3b7365e1134",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
